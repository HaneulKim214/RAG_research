{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e33cc102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from numpy.linalg import norm\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116d35ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure this path points to your downloaded and unzipped GloVe file.\n",
    "GLOVE_FILE_PATH = '/Users/haneulkim/Desktop/data/wiki_giga_2024_50_MFT20_vectors_seed_123_alpha_0.75_eta_0.075_combined.txt'\n",
    "\n",
    "def load_glove_embeddings(file_path):\n",
    "    \"\"\"\n",
    "    Loads GloVe word embeddings from a text file.\n",
    "    GloVe is an unsupervised learning algorithm for obtaining vector\n",
    "    representations for words [5, 6].\n",
    "    \"\"\"\n",
    "    words, vectors = [], []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word, embs = values[0], values[1:]\n",
    "            try:\n",
    "                vector = np.asarray(embs, \"float32\")\n",
    "                words.append(word)\n",
    "                vectors.append(vector)\n",
    "            except ValueError:\n",
    "                continue\n",
    "    embeddings_df = pd.DataFrame({\"word\": words, \"vector\": vectors})\n",
    "    return embeddings_df\n",
    "\n",
    "embeddings_df = load_glove_embeddings(GLOVE_FILE_PATH)\n",
    "embeddings_df['dimensions'] = embeddings_df['vector'].apply(lambda x: x.shape[0])\n",
    "embeddings_df = embeddings_df[embeddings_df['dimensions'] == 50].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b61a61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subvector_dim:  5\n",
      "(10000, 50)\n"
     ]
    }
   ],
   "source": [
    "n_items = 10_000\n",
    "n_subvectors = 10    \n",
    "n_clusters = 8       # K: Number of centroids per subspace (4-bit quantization: 2^4 = 0-15 integer points)\n",
    "eta = 2.04           # Anisotropic weighting factor\n",
    "\n",
    "item_embeddings = np.stack(embeddings_df.iloc[:n_items]['vector'].values)\n",
    "item_embeddings /= norm(item_embeddings, axis=1, keepdims=True)\n",
    "embedding_dim = item_embeddings.shape[1]\n",
    "\n",
    "# Calculate the dimension of each subvector\n",
    "subvector_dim = embedding_dim // n_subvectors\n",
    "\n",
    "print(\"subvector_dim: \", subvector_dim)\n",
    "print(item_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "571afd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 50)\n"
     ]
    }
   ],
   "source": [
    "# The ScaNN paper notes that for MIPS tasks equivalent to cosine similarity,\n",
    "# data is unit-normalized. This is a common practice [9].\n",
    "item_embeddings = np.stack(embeddings_df.iloc[:n_items]['vector'].values)\n",
    "item_embeddings /= norm(item_embeddings, axis=1, keepdims=True)\n",
    "print(item_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c487fe",
   "metadata": {},
   "source": [
    "How we learn the codebooks(finding optimal cluster) differentiates various quantization methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37aff7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subspaces = [[] for j in range(n_subvectors)]\n",
    "for v in item_embeddings:\n",
    "    for j in range(n_subvectors):\n",
    "        subvector = v[j * subvector_dim:(j + 1) * subvector_dim]\n",
    "        subspaces[j].append(subvector)\n",
    "subspaces = [np.array(s) for s in subspaces]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6424aade",
   "metadata": {},
   "source": [
    "# 1. Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3205d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (np.append(subspaces[0][0], subspaces[1][0]) == item_embeddings[0][:subvector_dim*2]).all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a3efa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(vector, codebooks):\n",
    "    codes = []\n",
    "    for j in range(n_subvectors):\n",
    "        sub_vec = vector[j * subvector_dim:(j + 1) * subvector_dim]\n",
    "        codebook_subspace_j = codebooks[j] \n",
    "        # find the nearest centroid for each subvector using euclidean distance.\n",
    "        dist = np.sum((codebook_subspace_j - sub_vec) ** 2, axis=1)\n",
    "        codes.append(np.argmin(dist)) # assigning index of the nearest centroid.\n",
    "    return np.array(codes)\n",
    "\n",
    "def decode(q_vector, codebooks):\n",
    "    \"\"\"\n",
    "    Note, sum of local errors is same as concatenating then computing distance.\n",
    "    \"\"\"\n",
    "    reconstructed_subvecs = []\n",
    "    for j in range(n_subvectors):\n",
    "        # get centroid of cluster(code) that q_vector was assigned to.\n",
    "        centroid = codebooks[j][q_vector[j]]\n",
    "        reconstructed_subvecs.append(centroid)\n",
    "    return np.concatenate(reconstructed_subvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c4fd56",
   "metadata": {},
   "source": [
    "## 1.1. Standard Product Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "371310f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster each subspace of 5-dimensions into 8 clusters\n",
      "(8, 5)\n",
      "number of kmeans iterations: 33\n"
     ]
    }
   ],
   "source": [
    "# Training: Standard PQ: Isotropic loss function (a.k.a. Euclidean distance loss)\n",
    "# codebook_size = number of clusters\n",
    "codebooks = [] \n",
    "verbose=False\n",
    "print(f\"cluster each subspace of {subvector_dim}-dimensions into {n_clusters} clusters\")\n",
    "for j, subspace in enumerate(subspaces):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, \n",
    "        init='k-means++', n_init=1, max_iter=300, verbose=verbose).fit(subspace)\n",
    "    codebooks.append(kmeans.cluster_centers_)\n",
    "\n",
    "\n",
    "print(codebooks[0].shape)\n",
    "\n",
    "print(f\"number of kmeans iterations: {kmeans.n_iter_}\")\n",
    "# so for each (10000, 16) subspace we have 10 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9213c34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 50)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_vectors = []\n",
    "for v in item_embeddings:\n",
    "    q_vec = encode(v, codebooks)\n",
    "    q_vectors.append(q_vec)\n",
    "q_vectors = np.array(q_vectors, dtype=np.int8)\n",
    "\n",
    "reconstructed_vectors = []  \n",
    "for q_vec in q_vectors:\n",
    "    reconstructed_vector = decode(q_vec, codebooks)\n",
    "    reconstructed_vectors.append(reconstructed_vector)\n",
    "reconstructed_vectors = np.array(reconstructed_vectors)\n",
    "reconstructed_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4809f291",
   "metadata": {},
   "source": [
    "## 1.2. Quantization w anisotropic loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96e86770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anisotropic_loss(residuals, x, eta=4.125, verbose=False):\n",
    "    x_norm_sq = np.sum(x**2, axis=-1, keepdims=True)\n",
    "    # Avoid division by zero for zero-norm vectors\n",
    "      # our numerator is inner_prod which will be 0 if x is 0 vector. so when we divide\n",
    "      # by x_norm_sq 0 vector should get 0. In order to do that, we set x_norm_sq to 1 when it is 0.\n",
    "    x_norm_sq[x_norm_sq == 0] = 1.0\n",
    "\n",
    "    # a1b2 + a2b2+ ... + anbn\n",
    "    # (N, k, d) * (N, 1, d) -> (N, k, d) => for all N rows, d is projection of residuals onto x.\n",
    "    inner_prod = np.sum(residuals * x, axis=-1, keepdims=True)\n",
    "    if verbose:\n",
    "        print(\"residuals * x.shape: \", (residuals * x).shape)\n",
    "        print(\"inner_prod.shape: \", inner_prod.shape)\n",
    "\n",
    "    r_parallel = inner_prod / x_norm_sq * x\n",
    "    r_orthogonal = residuals - r_parallel\n",
    "    if verbose:\n",
    "        print(\"r_parallel.shape: \", r_parallel.shape)\n",
    "        print(\"r_orthogonal.shape: \", r_orthogonal.shape)\n",
    "\n",
    "    r_parallel_sq_norm = np.sum(r_parallel**2, axis=-1, keepdims=True)\n",
    "    r_orthogonal_sq_norm = np.sum(r_orthogonal**2, axis=-1, keepdims=True)\n",
    "    if verbose:\n",
    "        print(\"r_parallel_sq_norm.shape: \", r_parallel_sq_norm.shape)\n",
    "        print(\"r_orthogonal_sq_norm.shape: \", r_orthogonal_sq_norm.shape)\n",
    "    # --- Step 4: Combine into the final anisotropic loss ---\n",
    "    # This is the final loss function from the paper [3, 4].\n",
    "    # ` ∝ η * ||r‖(xi, x̃i)||² + ||r⊥(xi, x̃i)||²\n",
    "    # Paper defines eta as ratio of parallel and orthogonal components (eta = h‖ / h⊥). section 3.2.\n",
    "     # This allows us to avoid computing complex integrals.\n",
    "     # Refer to my note.\n",
    "    return eta * r_parallel_sq_norm + r_orthogonal_sq_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66190339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Training subspace 0 --\n",
      "Iter 1/100 | Avg. Anisotropic Loss: 0.080056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2/100 | Avg. Anisotropic Loss: 0.060392\n",
      "Iter 3/100 | Avg. Anisotropic Loss: 0.055772\n",
      "Iter 4/100 | Avg. Anisotropic Loss: 0.054222\n",
      "Iter 5/100 | Avg. Anisotropic Loss: 0.053536\n",
      "Iter 6/100 | Avg. Anisotropic Loss: 0.052996\n",
      "Iter 7/100 | Avg. Anisotropic Loss: 0.052434\n",
      "Iter 8/100 | Avg. Anisotropic Loss: 0.051923\n",
      "Iter 9/100 | Avg. Anisotropic Loss: 0.051473\n",
      "Iter 10/100 | Avg. Anisotropic Loss: 0.051070\n",
      "Iter 11/100 | Avg. Anisotropic Loss: 0.050708\n",
      "Iter 12/100 | Avg. Anisotropic Loss: 0.050469\n",
      "Iter 13/100 | Avg. Anisotropic Loss: 0.050314\n",
      "Iter 14/100 | Avg. Anisotropic Loss: 0.050216\n",
      "Iter 15/100 | Avg. Anisotropic Loss: 0.050152\n",
      "Iter 16/100 | Avg. Anisotropic Loss: 0.050099\n",
      "Iter 17/100 | Avg. Anisotropic Loss: 0.050065\n",
      "Iter 18/100 | Avg. Anisotropic Loss: 0.050043\n",
      "Iter 19/100 | Avg. Anisotropic Loss: 0.050032\n",
      "Iter 20/100 | Avg. Anisotropic Loss: 0.050026\n",
      "Iter 21/100 | Avg. Anisotropic Loss: 0.050021\n",
      "Iter 22/100 | Avg. Anisotropic Loss: 0.050013\n",
      "Iter 23/100 | Avg. Anisotropic Loss: 0.050007\n",
      "Iter 24/100 | Avg. Anisotropic Loss: 0.049998\n",
      "Iter 25/100 | Avg. Anisotropic Loss: 0.049984\n",
      "Iter 26/100 | Avg. Anisotropic Loss: 0.049971\n",
      "Iter 27/100 | Avg. Anisotropic Loss: 0.049957\n",
      "Iter 28/100 | Avg. Anisotropic Loss: 0.049942\n",
      "Iter 29/100 | Avg. Anisotropic Loss: 0.049933\n",
      "Iter 30/100 | Avg. Anisotropic Loss: 0.049923\n",
      "Iter 31/100 | Avg. Anisotropic Loss: 0.049916\n",
      "Iter 32/100 | Avg. Anisotropic Loss: 0.049912\n",
      "Iter 33/100 | Avg. Anisotropic Loss: 0.049910\n",
      "Iter 34/100 | Avg. Anisotropic Loss: 0.049908\n",
      "Iter 35/100 | Avg. Anisotropic Loss: 0.049908\n",
      "Iter 36/100 | Avg. Anisotropic Loss: 0.049907\n",
      "Iter 37/100 | Avg. Anisotropic Loss: 0.049905\n",
      "Iter 38/100 | Avg. Anisotropic Loss: 0.049903\n",
      "Iter 39/100 | Avg. Anisotropic Loss: 0.049901\n",
      "Iter 40/100 | Avg. Anisotropic Loss: 0.049899\n",
      "Iter 41/100 | Avg. Anisotropic Loss: 0.049898\n",
      "Iter 42/100 | Avg. Anisotropic Loss: 0.049898\n",
      "Iter 43/100 | Avg. Anisotropic Loss: 0.049898\n",
      "Iter 44/100 | Avg. Anisotropic Loss: 0.049898\n",
      "Iter 45/100 | Avg. Anisotropic Loss: 0.049898\n",
      "Iter 46/100 | Avg. Anisotropic Loss: 0.049898\n",
      "Iter 47/100 | Avg. Anisotropic Loss: 0.049897\n",
      "Iter 48/100 | Avg. Anisotropic Loss: 0.049897\n",
      "Iter 49/100 | Avg. Anisotropic Loss: 0.049897\n",
      "Iter 50/100 | Avg. Anisotropic Loss: 0.049897\n",
      "Iter 51/100 | Avg. Anisotropic Loss: 0.049897\n",
      "Iter 52/100 | Avg. Anisotropic Loss: 0.049897\n",
      "Iter 53/100 | Avg. Anisotropic Loss: 0.049897\n",
      "subspace 0 - Converged after 53 iterations.\n",
      "--Training subspace 1 --\n",
      "Iter 1/100 | Avg. Anisotropic Loss: 0.076688\n",
      "Iter 2/100 | Avg. Anisotropic Loss: 0.057407\n",
      "Iter 3/100 | Avg. Anisotropic Loss: 0.053981\n",
      "Iter 4/100 | Avg. Anisotropic Loss: 0.052820\n",
      "Iter 5/100 | Avg. Anisotropic Loss: 0.052288\n",
      "Iter 6/100 | Avg. Anisotropic Loss: 0.051905\n",
      "Iter 7/100 | Avg. Anisotropic Loss: 0.051682\n",
      "Iter 8/100 | Avg. Anisotropic Loss: 0.051549\n",
      "Iter 9/100 | Avg. Anisotropic Loss: 0.051457\n",
      "Iter 10/100 | Avg. Anisotropic Loss: 0.051397\n",
      "Iter 11/100 | Avg. Anisotropic Loss: 0.051351\n",
      "Iter 12/100 | Avg. Anisotropic Loss: 0.051315\n",
      "Iter 13/100 | Avg. Anisotropic Loss: 0.051283\n",
      "Iter 14/100 | Avg. Anisotropic Loss: 0.051255\n",
      "Iter 15/100 | Avg. Anisotropic Loss: 0.051225\n",
      "Iter 16/100 | Avg. Anisotropic Loss: 0.051196\n",
      "Iter 17/100 | Avg. Anisotropic Loss: 0.051160\n",
      "Iter 18/100 | Avg. Anisotropic Loss: 0.051130\n",
      "Iter 19/100 | Avg. Anisotropic Loss: 0.051097\n",
      "Iter 20/100 | Avg. Anisotropic Loss: 0.051070\n",
      "Iter 21/100 | Avg. Anisotropic Loss: 0.051038\n",
      "Iter 22/100 | Avg. Anisotropic Loss: 0.051015\n",
      "Iter 23/100 | Avg. Anisotropic Loss: 0.051000\n",
      "Iter 24/100 | Avg. Anisotropic Loss: 0.050990\n",
      "Iter 25/100 | Avg. Anisotropic Loss: 0.050979\n",
      "Iter 26/100 | Avg. Anisotropic Loss: 0.050968\n",
      "Iter 27/100 | Avg. Anisotropic Loss: 0.050951\n",
      "Iter 28/100 | Avg. Anisotropic Loss: 0.050929\n",
      "Iter 29/100 | Avg. Anisotropic Loss: 0.050905\n",
      "Iter 30/100 | Avg. Anisotropic Loss: 0.050878\n",
      "Iter 31/100 | Avg. Anisotropic Loss: 0.050850\n",
      "Iter 32/100 | Avg. Anisotropic Loss: 0.050828\n",
      "Iter 33/100 | Avg. Anisotropic Loss: 0.050814\n",
      "Iter 34/100 | Avg. Anisotropic Loss: 0.050799\n",
      "Iter 35/100 | Avg. Anisotropic Loss: 0.050785\n",
      "Iter 36/100 | Avg. Anisotropic Loss: 0.050770\n",
      "Iter 37/100 | Avg. Anisotropic Loss: 0.050756\n",
      "Iter 38/100 | Avg. Anisotropic Loss: 0.050744\n",
      "Iter 39/100 | Avg. Anisotropic Loss: 0.050734\n",
      "Iter 40/100 | Avg. Anisotropic Loss: 0.050724\n",
      "Iter 41/100 | Avg. Anisotropic Loss: 0.050712\n",
      "Iter 42/100 | Avg. Anisotropic Loss: 0.050701\n",
      "Iter 43/100 | Avg. Anisotropic Loss: 0.050683\n",
      "Iter 44/100 | Avg. Anisotropic Loss: 0.050666\n",
      "Iter 45/100 | Avg. Anisotropic Loss: 0.050653\n",
      "Iter 46/100 | Avg. Anisotropic Loss: 0.050645\n",
      "Iter 47/100 | Avg. Anisotropic Loss: 0.050636\n",
      "Iter 48/100 | Avg. Anisotropic Loss: 0.050625\n",
      "Iter 49/100 | Avg. Anisotropic Loss: 0.050610\n",
      "Iter 50/100 | Avg. Anisotropic Loss: 0.050594\n",
      "Iter 51/100 | Avg. Anisotropic Loss: 0.050574\n",
      "Iter 52/100 | Avg. Anisotropic Loss: 0.050545\n",
      "Iter 53/100 | Avg. Anisotropic Loss: 0.050496\n",
      "Iter 54/100 | Avg. Anisotropic Loss: 0.050433\n",
      "Iter 55/100 | Avg. Anisotropic Loss: 0.050363\n",
      "Iter 56/100 | Avg. Anisotropic Loss: 0.050282\n",
      "Iter 57/100 | Avg. Anisotropic Loss: 0.050197\n",
      "Iter 58/100 | Avg. Anisotropic Loss: 0.050088\n",
      "Iter 59/100 | Avg. Anisotropic Loss: 0.049927\n",
      "Iter 60/100 | Avg. Anisotropic Loss: 0.049731\n",
      "Iter 61/100 | Avg. Anisotropic Loss: 0.049570\n",
      "Iter 62/100 | Avg. Anisotropic Loss: 0.049467\n",
      "Iter 63/100 | Avg. Anisotropic Loss: 0.049397\n",
      "Iter 64/100 | Avg. Anisotropic Loss: 0.049350\n",
      "Iter 65/100 | Avg. Anisotropic Loss: 0.049324\n",
      "Iter 66/100 | Avg. Anisotropic Loss: 0.049307\n",
      "Iter 67/100 | Avg. Anisotropic Loss: 0.049293\n",
      "Iter 68/100 | Avg. Anisotropic Loss: 0.049281\n",
      "Iter 69/100 | Avg. Anisotropic Loss: 0.049269\n",
      "Iter 70/100 | Avg. Anisotropic Loss: 0.049260\n",
      "Iter 71/100 | Avg. Anisotropic Loss: 0.049253\n",
      "Iter 72/100 | Avg. Anisotropic Loss: 0.049248\n",
      "Iter 73/100 | Avg. Anisotropic Loss: 0.049246\n",
      "Iter 74/100 | Avg. Anisotropic Loss: 0.049244\n",
      "Iter 75/100 | Avg. Anisotropic Loss: 0.049243\n",
      "Iter 76/100 | Avg. Anisotropic Loss: 0.049242\n",
      "Iter 77/100 | Avg. Anisotropic Loss: 0.049241\n",
      "Iter 78/100 | Avg. Anisotropic Loss: 0.049240\n",
      "Iter 79/100 | Avg. Anisotropic Loss: 0.049239\n",
      "Iter 80/100 | Avg. Anisotropic Loss: 0.049237\n",
      "Iter 81/100 | Avg. Anisotropic Loss: 0.049235\n",
      "Iter 82/100 | Avg. Anisotropic Loss: 0.049235\n",
      "Iter 83/100 | Avg. Anisotropic Loss: 0.049234\n",
      "Iter 84/100 | Avg. Anisotropic Loss: 0.049234\n",
      "Iter 85/100 | Avg. Anisotropic Loss: 0.049234\n",
      "Iter 86/100 | Avg. Anisotropic Loss: 0.049233\n",
      "Iter 87/100 | Avg. Anisotropic Loss: 0.049232\n",
      "Iter 88/100 | Avg. Anisotropic Loss: 0.049232\n",
      "Iter 89/100 | Avg. Anisotropic Loss: 0.049231\n",
      "Iter 90/100 | Avg. Anisotropic Loss: 0.049231\n",
      "Iter 91/100 | Avg. Anisotropic Loss: 0.049231\n",
      "Iter 92/100 | Avg. Anisotropic Loss: 0.049231\n",
      "subspace 1 - Converged after 92 iterations.\n",
      "--Training subspace 2 --\n",
      "Iter 1/100 | Avg. Anisotropic Loss: 0.070785\n",
      "Iter 2/100 | Avg. Anisotropic Loss: 0.060255\n",
      "Iter 3/100 | Avg. Anisotropic Loss: 0.058227\n",
      "Iter 4/100 | Avg. Anisotropic Loss: 0.057560\n",
      "Iter 5/100 | Avg. Anisotropic Loss: 0.057189\n",
      "Iter 6/100 | Avg. Anisotropic Loss: 0.056938\n",
      "Iter 7/100 | Avg. Anisotropic Loss: 0.056763\n",
      "Iter 8/100 | Avg. Anisotropic Loss: 0.056650\n",
      "Iter 9/100 | Avg. Anisotropic Loss: 0.056577\n",
      "Iter 10/100 | Avg. Anisotropic Loss: 0.056526\n",
      "Iter 11/100 | Avg. Anisotropic Loss: 0.056483\n",
      "Iter 12/100 | Avg. Anisotropic Loss: 0.056453\n",
      "Iter 13/100 | Avg. Anisotropic Loss: 0.056425\n",
      "Iter 14/100 | Avg. Anisotropic Loss: 0.056401\n",
      "Iter 15/100 | Avg. Anisotropic Loss: 0.056385\n",
      "Iter 16/100 | Avg. Anisotropic Loss: 0.056374\n",
      "Iter 17/100 | Avg. Anisotropic Loss: 0.056366\n",
      "Iter 18/100 | Avg. Anisotropic Loss: 0.056357\n",
      "Iter 19/100 | Avg. Anisotropic Loss: 0.056351\n",
      "Iter 20/100 | Avg. Anisotropic Loss: 0.056345\n",
      "Iter 21/100 | Avg. Anisotropic Loss: 0.056342\n",
      "Iter 22/100 | Avg. Anisotropic Loss: 0.056336\n",
      "Iter 23/100 | Avg. Anisotropic Loss: 0.056329\n",
      "Iter 24/100 | Avg. Anisotropic Loss: 0.056324\n",
      "Iter 25/100 | Avg. Anisotropic Loss: 0.056319\n",
      "Iter 26/100 | Avg. Anisotropic Loss: 0.056312\n",
      "Iter 27/100 | Avg. Anisotropic Loss: 0.056303\n",
      "Iter 28/100 | Avg. Anisotropic Loss: 0.056292\n",
      "Iter 29/100 | Avg. Anisotropic Loss: 0.056282\n",
      "Iter 30/100 | Avg. Anisotropic Loss: 0.056273\n",
      "Iter 31/100 | Avg. Anisotropic Loss: 0.056261\n",
      "Iter 32/100 | Avg. Anisotropic Loss: 0.056246\n",
      "Iter 33/100 | Avg. Anisotropic Loss: 0.056227\n",
      "Iter 34/100 | Avg. Anisotropic Loss: 0.056212\n",
      "Iter 35/100 | Avg. Anisotropic Loss: 0.056199\n",
      "Iter 36/100 | Avg. Anisotropic Loss: 0.056188\n",
      "Iter 37/100 | Avg. Anisotropic Loss: 0.056179\n",
      "Iter 38/100 | Avg. Anisotropic Loss: 0.056170\n",
      "Iter 39/100 | Avg. Anisotropic Loss: 0.056165\n",
      "Iter 40/100 | Avg. Anisotropic Loss: 0.056161\n",
      "Iter 41/100 | Avg. Anisotropic Loss: 0.056156\n",
      "Iter 42/100 | Avg. Anisotropic Loss: 0.056151\n",
      "Iter 43/100 | Avg. Anisotropic Loss: 0.056146\n",
      "Iter 44/100 | Avg. Anisotropic Loss: 0.056141\n",
      "Iter 45/100 | Avg. Anisotropic Loss: 0.056137\n",
      "Iter 46/100 | Avg. Anisotropic Loss: 0.056133\n",
      "Iter 47/100 | Avg. Anisotropic Loss: 0.056131\n",
      "Iter 48/100 | Avg. Anisotropic Loss: 0.056130\n",
      "Iter 49/100 | Avg. Anisotropic Loss: 0.056129\n",
      "Iter 50/100 | Avg. Anisotropic Loss: 0.056127\n",
      "Iter 51/100 | Avg. Anisotropic Loss: 0.056126\n",
      "Iter 52/100 | Avg. Anisotropic Loss: 0.056125\n",
      "Iter 53/100 | Avg. Anisotropic Loss: 0.056124\n",
      "Iter 54/100 | Avg. Anisotropic Loss: 0.056123\n",
      "Iter 55/100 | Avg. Anisotropic Loss: 0.056121\n",
      "Iter 56/100 | Avg. Anisotropic Loss: 0.056119\n",
      "Iter 57/100 | Avg. Anisotropic Loss: 0.056115\n",
      "Iter 58/100 | Avg. Anisotropic Loss: 0.056114\n",
      "Iter 59/100 | Avg. Anisotropic Loss: 0.056112\n",
      "Iter 60/100 | Avg. Anisotropic Loss: 0.056110\n",
      "Iter 61/100 | Avg. Anisotropic Loss: 0.056108\n",
      "Iter 62/100 | Avg. Anisotropic Loss: 0.056105\n",
      "Iter 63/100 | Avg. Anisotropic Loss: 0.056102\n",
      "Iter 64/100 | Avg. Anisotropic Loss: 0.056099\n",
      "Iter 65/100 | Avg. Anisotropic Loss: 0.056097\n",
      "Iter 66/100 | Avg. Anisotropic Loss: 0.056095\n",
      "Iter 67/100 | Avg. Anisotropic Loss: 0.056093\n",
      "Iter 68/100 | Avg. Anisotropic Loss: 0.056092\n",
      "Iter 69/100 | Avg. Anisotropic Loss: 0.056091\n",
      "Iter 70/100 | Avg. Anisotropic Loss: 0.056088\n",
      "Iter 71/100 | Avg. Anisotropic Loss: 0.056085\n",
      "Iter 72/100 | Avg. Anisotropic Loss: 0.056080\n",
      "Iter 73/100 | Avg. Anisotropic Loss: 0.056075\n",
      "Iter 74/100 | Avg. Anisotropic Loss: 0.056070\n",
      "Iter 75/100 | Avg. Anisotropic Loss: 0.056065\n",
      "Iter 76/100 | Avg. Anisotropic Loss: 0.056060\n",
      "Iter 77/100 | Avg. Anisotropic Loss: 0.056057\n",
      "Iter 78/100 | Avg. Anisotropic Loss: 0.056055\n",
      "Iter 79/100 | Avg. Anisotropic Loss: 0.056053\n",
      "Iter 80/100 | Avg. Anisotropic Loss: 0.056050\n",
      "Iter 81/100 | Avg. Anisotropic Loss: 0.056049\n",
      "Iter 82/100 | Avg. Anisotropic Loss: 0.056047\n",
      "Iter 83/100 | Avg. Anisotropic Loss: 0.056045\n",
      "Iter 84/100 | Avg. Anisotropic Loss: 0.056045\n",
      "Iter 85/100 | Avg. Anisotropic Loss: 0.056044\n",
      "Iter 86/100 | Avg. Anisotropic Loss: 0.056044\n",
      "Iter 87/100 | Avg. Anisotropic Loss: 0.056043\n",
      "Iter 88/100 | Avg. Anisotropic Loss: 0.056043\n",
      "Iter 89/100 | Avg. Anisotropic Loss: 0.056042\n",
      "Iter 90/100 | Avg. Anisotropic Loss: 0.056040\n",
      "Iter 91/100 | Avg. Anisotropic Loss: 0.056039\n",
      "Iter 92/100 | Avg. Anisotropic Loss: 0.056038\n",
      "Iter 93/100 | Avg. Anisotropic Loss: 0.056038\n",
      "Iter 94/100 | Avg. Anisotropic Loss: 0.056037\n",
      "Iter 95/100 | Avg. Anisotropic Loss: 0.056037\n",
      "Iter 96/100 | Avg. Anisotropic Loss: 0.056036\n",
      "Iter 97/100 | Avg. Anisotropic Loss: 0.056035\n",
      "Iter 98/100 | Avg. Anisotropic Loss: 0.056035\n",
      "Iter 99/100 | Avg. Anisotropic Loss: 0.056034\n",
      "Iter 100/100 | Avg. Anisotropic Loss: 0.056034\n",
      "--Training subspace 3 --\n",
      "Iter 1/100 | Avg. Anisotropic Loss: 0.069926\n",
      "Iter 2/100 | Avg. Anisotropic Loss: 0.053241\n",
      "Iter 3/100 | Avg. Anisotropic Loss: 0.050249\n",
      "Iter 4/100 | Avg. Anisotropic Loss: 0.049010\n",
      "Iter 5/100 | Avg. Anisotropic Loss: 0.048272\n",
      "Iter 6/100 | Avg. Anisotropic Loss: 0.047867\n",
      "Iter 7/100 | Avg. Anisotropic Loss: 0.047597\n",
      "Iter 8/100 | Avg. Anisotropic Loss: 0.047412\n",
      "Iter 9/100 | Avg. Anisotropic Loss: 0.047238\n",
      "Iter 10/100 | Avg. Anisotropic Loss: 0.047120\n",
      "Iter 11/100 | Avg. Anisotropic Loss: 0.047007\n",
      "Iter 12/100 | Avg. Anisotropic Loss: 0.046936\n",
      "Iter 13/100 | Avg. Anisotropic Loss: 0.046878\n",
      "Iter 14/100 | Avg. Anisotropic Loss: 0.046832\n",
      "Iter 15/100 | Avg. Anisotropic Loss: 0.046800\n",
      "Iter 16/100 | Avg. Anisotropic Loss: 0.046766\n",
      "Iter 17/100 | Avg. Anisotropic Loss: 0.046741\n",
      "Iter 18/100 | Avg. Anisotropic Loss: 0.046714\n",
      "Iter 19/100 | Avg. Anisotropic Loss: 0.046695\n",
      "Iter 20/100 | Avg. Anisotropic Loss: 0.046683\n",
      "Iter 21/100 | Avg. Anisotropic Loss: 0.046675\n",
      "Iter 22/100 | Avg. Anisotropic Loss: 0.046668\n",
      "Iter 23/100 | Avg. Anisotropic Loss: 0.046659\n",
      "Iter 24/100 | Avg. Anisotropic Loss: 0.046653\n",
      "Iter 25/100 | Avg. Anisotropic Loss: 0.046644\n",
      "Iter 26/100 | Avg. Anisotropic Loss: 0.046634\n",
      "Iter 27/100 | Avg. Anisotropic Loss: 0.046627\n",
      "Iter 28/100 | Avg. Anisotropic Loss: 0.046619\n",
      "Iter 29/100 | Avg. Anisotropic Loss: 0.046607\n",
      "Iter 30/100 | Avg. Anisotropic Loss: 0.046598\n",
      "Iter 31/100 | Avg. Anisotropic Loss: 0.046590\n",
      "Iter 32/100 | Avg. Anisotropic Loss: 0.046580\n",
      "Iter 33/100 | Avg. Anisotropic Loss: 0.046566\n",
      "Iter 34/100 | Avg. Anisotropic Loss: 0.046556\n",
      "Iter 35/100 | Avg. Anisotropic Loss: 0.046541\n",
      "Iter 36/100 | Avg. Anisotropic Loss: 0.046517\n",
      "Iter 37/100 | Avg. Anisotropic Loss: 0.046499\n",
      "Iter 38/100 | Avg. Anisotropic Loss: 0.046490\n",
      "Iter 39/100 | Avg. Anisotropic Loss: 0.046484\n",
      "Iter 40/100 | Avg. Anisotropic Loss: 0.046477\n",
      "Iter 41/100 | Avg. Anisotropic Loss: 0.046471\n",
      "Iter 42/100 | Avg. Anisotropic Loss: 0.046465\n",
      "Iter 43/100 | Avg. Anisotropic Loss: 0.046459\n",
      "Iter 44/100 | Avg. Anisotropic Loss: 0.046448\n",
      "Iter 45/100 | Avg. Anisotropic Loss: 0.046438\n",
      "Iter 46/100 | Avg. Anisotropic Loss: 0.046429\n",
      "Iter 47/100 | Avg. Anisotropic Loss: 0.046422\n",
      "Iter 48/100 | Avg. Anisotropic Loss: 0.046416\n",
      "Iter 49/100 | Avg. Anisotropic Loss: 0.046412\n",
      "Iter 50/100 | Avg. Anisotropic Loss: 0.046410\n",
      "Iter 51/100 | Avg. Anisotropic Loss: 0.046407\n",
      "Iter 52/100 | Avg. Anisotropic Loss: 0.046405\n",
      "Iter 53/100 | Avg. Anisotropic Loss: 0.046404\n",
      "Iter 54/100 | Avg. Anisotropic Loss: 0.046404\n",
      "Iter 55/100 | Avg. Anisotropic Loss: 0.046403\n",
      "Iter 56/100 | Avg. Anisotropic Loss: 0.046402\n",
      "Iter 57/100 | Avg. Anisotropic Loss: 0.046401\n",
      "Iter 58/100 | Avg. Anisotropic Loss: 0.046401\n",
      "Iter 59/100 | Avg. Anisotropic Loss: 0.046400\n",
      "Iter 60/100 | Avg. Anisotropic Loss: 0.046400\n",
      "Iter 61/100 | Avg. Anisotropic Loss: 0.046400\n",
      "Iter 62/100 | Avg. Anisotropic Loss: 0.046400\n",
      "Iter 63/100 | Avg. Anisotropic Loss: 0.046400\n",
      "Iter 64/100 | Avg. Anisotropic Loss: 0.046400\n",
      "subspace 3 - Converged after 64 iterations.\n",
      "--Training subspace 4 --\n",
      "Iter 1/100 | Avg. Anisotropic Loss: 0.072498\n",
      "Iter 2/100 | Avg. Anisotropic Loss: 0.059292\n",
      "Iter 3/100 | Avg. Anisotropic Loss: 0.056001\n",
      "Iter 4/100 | Avg. Anisotropic Loss: 0.054774\n",
      "Iter 5/100 | Avg. Anisotropic Loss: 0.054104\n",
      "Iter 6/100 | Avg. Anisotropic Loss: 0.053704\n",
      "Iter 7/100 | Avg. Anisotropic Loss: 0.053451\n",
      "Iter 8/100 | Avg. Anisotropic Loss: 0.053258\n",
      "Iter 9/100 | Avg. Anisotropic Loss: 0.053108\n",
      "Iter 10/100 | Avg. Anisotropic Loss: 0.053001\n",
      "Iter 11/100 | Avg. Anisotropic Loss: 0.052920\n",
      "Iter 12/100 | Avg. Anisotropic Loss: 0.052871\n",
      "Iter 13/100 | Avg. Anisotropic Loss: 0.052842\n",
      "Iter 14/100 | Avg. Anisotropic Loss: 0.052817\n",
      "Iter 15/100 | Avg. Anisotropic Loss: 0.052800\n",
      "Iter 16/100 | Avg. Anisotropic Loss: 0.052784\n",
      "Iter 17/100 | Avg. Anisotropic Loss: 0.052771\n",
      "Iter 18/100 | Avg. Anisotropic Loss: 0.052761\n",
      "Iter 19/100 | Avg. Anisotropic Loss: 0.052754\n",
      "Iter 20/100 | Avg. Anisotropic Loss: 0.052750\n",
      "Iter 21/100 | Avg. Anisotropic Loss: 0.052747\n",
      "Iter 22/100 | Avg. Anisotropic Loss: 0.052744\n",
      "Iter 23/100 | Avg. Anisotropic Loss: 0.052742\n",
      "Iter 24/100 | Avg. Anisotropic Loss: 0.052739\n",
      "Iter 25/100 | Avg. Anisotropic Loss: 0.052738\n",
      "Iter 26/100 | Avg. Anisotropic Loss: 0.052737\n",
      "Iter 27/100 | Avg. Anisotropic Loss: 0.052736\n",
      "Iter 28/100 | Avg. Anisotropic Loss: 0.052736\n",
      "Iter 29/100 | Avg. Anisotropic Loss: 0.052734\n",
      "Iter 30/100 | Avg. Anisotropic Loss: 0.052733\n",
      "Iter 31/100 | Avg. Anisotropic Loss: 0.052733\n",
      "Iter 32/100 | Avg. Anisotropic Loss: 0.052731\n",
      "Iter 33/100 | Avg. Anisotropic Loss: 0.052729\n",
      "Iter 34/100 | Avg. Anisotropic Loss: 0.052727\n",
      "Iter 35/100 | Avg. Anisotropic Loss: 0.052727\n",
      "Iter 36/100 | Avg. Anisotropic Loss: 0.052726\n",
      "Iter 37/100 | Avg. Anisotropic Loss: 0.052724\n",
      "Iter 38/100 | Avg. Anisotropic Loss: 0.052723\n",
      "Iter 39/100 | Avg. Anisotropic Loss: 0.052722\n",
      "Iter 40/100 | Avg. Anisotropic Loss: 0.052721\n",
      "Iter 41/100 | Avg. Anisotropic Loss: 0.052720\n",
      "Iter 42/100 | Avg. Anisotropic Loss: 0.052720\n",
      "Iter 43/100 | Avg. Anisotropic Loss: 0.052720\n",
      "Iter 44/100 | Avg. Anisotropic Loss: 0.052720\n",
      "Iter 45/100 | Avg. Anisotropic Loss: 0.052720\n",
      "Iter 46/100 | Avg. Anisotropic Loss: 0.052720\n",
      "Iter 47/100 | Avg. Anisotropic Loss: 0.052720\n",
      "Iter 48/100 | Avg. Anisotropic Loss: 0.052719\n",
      "Iter 49/100 | Avg. Anisotropic Loss: 0.052719\n",
      "Iter 50/100 | Avg. Anisotropic Loss: 0.052719\n",
      "subspace 4 - Converged after 50 iterations.\n",
      "--Training subspace 5 --\n",
      "Iter 1/100 | Avg. Anisotropic Loss: 0.064479\n",
      "Iter 2/100 | Avg. Anisotropic Loss: 0.052928\n",
      "Iter 3/100 | Avg. Anisotropic Loss: 0.050957\n",
      "Iter 4/100 | Avg. Anisotropic Loss: 0.049875\n",
      "Iter 5/100 | Avg. Anisotropic Loss: 0.049034\n",
      "Iter 6/100 | Avg. Anisotropic Loss: 0.048440\n",
      "Iter 7/100 | Avg. Anisotropic Loss: 0.048065\n",
      "Iter 8/100 | Avg. Anisotropic Loss: 0.047811\n",
      "Iter 9/100 | Avg. Anisotropic Loss: 0.047651\n",
      "Iter 10/100 | Avg. Anisotropic Loss: 0.047538\n",
      "Iter 11/100 | Avg. Anisotropic Loss: 0.047470\n",
      "Iter 12/100 | Avg. Anisotropic Loss: 0.047423\n",
      "Iter 13/100 | Avg. Anisotropic Loss: 0.047375\n",
      "Iter 14/100 | Avg. Anisotropic Loss: 0.047336\n",
      "Iter 15/100 | Avg. Anisotropic Loss: 0.047307\n",
      "Iter 16/100 | Avg. Anisotropic Loss: 0.047288\n",
      "Iter 17/100 | Avg. Anisotropic Loss: 0.047269\n",
      "Iter 18/100 | Avg. Anisotropic Loss: 0.047254\n",
      "Iter 19/100 | Avg. Anisotropic Loss: 0.047238\n",
      "Iter 20/100 | Avg. Anisotropic Loss: 0.047215\n",
      "Iter 21/100 | Avg. Anisotropic Loss: 0.047190\n",
      "Iter 22/100 | Avg. Anisotropic Loss: 0.047169\n",
      "Iter 23/100 | Avg. Anisotropic Loss: 0.047148\n",
      "Iter 24/100 | Avg. Anisotropic Loss: 0.047135\n",
      "Iter 25/100 | Avg. Anisotropic Loss: 0.047126\n",
      "Iter 26/100 | Avg. Anisotropic Loss: 0.047117\n",
      "Iter 27/100 | Avg. Anisotropic Loss: 0.047107\n",
      "Iter 28/100 | Avg. Anisotropic Loss: 0.047098\n",
      "Iter 29/100 | Avg. Anisotropic Loss: 0.047088\n",
      "Iter 30/100 | Avg. Anisotropic Loss: 0.047075\n",
      "Iter 31/100 | Avg. Anisotropic Loss: 0.047055\n",
      "Iter 32/100 | Avg. Anisotropic Loss: 0.047039\n",
      "Iter 33/100 | Avg. Anisotropic Loss: 0.047031\n",
      "Iter 34/100 | Avg. Anisotropic Loss: 0.047022\n",
      "Iter 35/100 | Avg. Anisotropic Loss: 0.047017\n",
      "Iter 36/100 | Avg. Anisotropic Loss: 0.047008\n",
      "Iter 37/100 | Avg. Anisotropic Loss: 0.046994\n",
      "Iter 38/100 | Avg. Anisotropic Loss: 0.046979\n",
      "Iter 39/100 | Avg. Anisotropic Loss: 0.046971\n",
      "Iter 40/100 | Avg. Anisotropic Loss: 0.046965\n",
      "Iter 41/100 | Avg. Anisotropic Loss: 0.046960\n",
      "Iter 42/100 | Avg. Anisotropic Loss: 0.046955\n",
      "Iter 43/100 | Avg. Anisotropic Loss: 0.046951\n",
      "Iter 44/100 | Avg. Anisotropic Loss: 0.046947\n",
      "Iter 45/100 | Avg. Anisotropic Loss: 0.046942\n",
      "Iter 46/100 | Avg. Anisotropic Loss: 0.046937\n",
      "Iter 47/100 | Avg. Anisotropic Loss: 0.046934\n",
      "Iter 48/100 | Avg. Anisotropic Loss: 0.046930\n",
      "Iter 49/100 | Avg. Anisotropic Loss: 0.046928\n",
      "Iter 50/100 | Avg. Anisotropic Loss: 0.046926\n",
      "Iter 51/100 | Avg. Anisotropic Loss: 0.046924\n",
      "Iter 52/100 | Avg. Anisotropic Loss: 0.046923\n",
      "Iter 53/100 | Avg. Anisotropic Loss: 0.046921\n",
      "Iter 54/100 | Avg. Anisotropic Loss: 0.046918\n",
      "Iter 55/100 | Avg. Anisotropic Loss: 0.046915\n",
      "Iter 56/100 | Avg. Anisotropic Loss: 0.046911\n",
      "Iter 57/100 | Avg. Anisotropic Loss: 0.046909\n",
      "Iter 58/100 | Avg. Anisotropic Loss: 0.046907\n",
      "Iter 59/100 | Avg. Anisotropic Loss: 0.046903\n",
      "Iter 60/100 | Avg. Anisotropic Loss: 0.046899\n",
      "Iter 61/100 | Avg. Anisotropic Loss: 0.046897\n",
      "Iter 62/100 | Avg. Anisotropic Loss: 0.046895\n",
      "Iter 63/100 | Avg. Anisotropic Loss: 0.046893\n",
      "Iter 64/100 | Avg. Anisotropic Loss: 0.046891\n",
      "Iter 65/100 | Avg. Anisotropic Loss: 0.046890\n",
      "Iter 66/100 | Avg. Anisotropic Loss: 0.046889\n",
      "Iter 67/100 | Avg. Anisotropic Loss: 0.046888\n",
      "Iter 68/100 | Avg. Anisotropic Loss: 0.046888\n",
      "Iter 69/100 | Avg. Anisotropic Loss: 0.046887\n",
      "Iter 70/100 | Avg. Anisotropic Loss: 0.046887\n",
      "Iter 71/100 | Avg. Anisotropic Loss: 0.046886\n",
      "Iter 72/100 | Avg. Anisotropic Loss: 0.046886\n",
      "Iter 73/100 | Avg. Anisotropic Loss: 0.046885\n",
      "Iter 74/100 | Avg. Anisotropic Loss: 0.046884\n",
      "Iter 75/100 | Avg. Anisotropic Loss: 0.046883\n",
      "Iter 76/100 | Avg. Anisotropic Loss: 0.046882\n",
      "Iter 77/100 | Avg. Anisotropic Loss: 0.046882\n",
      "Iter 78/100 | Avg. Anisotropic Loss: 0.046880\n",
      "Iter 79/100 | Avg. Anisotropic Loss: 0.046876\n",
      "Iter 80/100 | Avg. Anisotropic Loss: 0.046874\n",
      "Iter 81/100 | Avg. Anisotropic Loss: 0.046871\n",
      "Iter 82/100 | Avg. Anisotropic Loss: 0.046867\n",
      "Iter 83/100 | Avg. Anisotropic Loss: 0.046865\n",
      "Iter 84/100 | Avg. Anisotropic Loss: 0.046863\n",
      "Iter 85/100 | Avg. Anisotropic Loss: 0.046861\n",
      "Iter 86/100 | Avg. Anisotropic Loss: 0.046859\n",
      "Iter 87/100 | Avg. Anisotropic Loss: 0.046858\n",
      "Iter 88/100 | Avg. Anisotropic Loss: 0.046856\n",
      "Iter 89/100 | Avg. Anisotropic Loss: 0.046855\n",
      "Iter 90/100 | Avg. Anisotropic Loss: 0.046854\n",
      "Iter 91/100 | Avg. Anisotropic Loss: 0.046853\n",
      "Iter 92/100 | Avg. Anisotropic Loss: 0.046852\n",
      "Iter 93/100 | Avg. Anisotropic Loss: 0.046850\n",
      "Iter 94/100 | Avg. Anisotropic Loss: 0.046846\n",
      "Iter 95/100 | Avg. Anisotropic Loss: 0.046839\n",
      "Iter 96/100 | Avg. Anisotropic Loss: 0.046832\n",
      "Iter 97/100 | Avg. Anisotropic Loss: 0.046826\n",
      "Iter 98/100 | Avg. Anisotropic Loss: 0.046821\n",
      "Iter 99/100 | Avg. Anisotropic Loss: 0.046817\n",
      "Iter 100/100 | Avg. Anisotropic Loss: 0.046813\n",
      "--Training subspace 6 --\n",
      "Iter 1/100 | Avg. Anisotropic Loss: 0.061363\n",
      "Iter 2/100 | Avg. Anisotropic Loss: 0.049493\n",
      "Iter 3/100 | Avg. Anisotropic Loss: 0.047602\n",
      "Iter 4/100 | Avg. Anisotropic Loss: 0.047088\n",
      "Iter 5/100 | Avg. Anisotropic Loss: 0.046841\n",
      "Iter 6/100 | Avg. Anisotropic Loss: 0.046657\n",
      "Iter 7/100 | Avg. Anisotropic Loss: 0.046501\n",
      "Iter 8/100 | Avg. Anisotropic Loss: 0.046368\n",
      "Iter 9/100 | Avg. Anisotropic Loss: 0.046241\n",
      "Iter 10/100 | Avg. Anisotropic Loss: 0.046118\n",
      "Iter 11/100 | Avg. Anisotropic Loss: 0.046031\n",
      "Iter 12/100 | Avg. Anisotropic Loss: 0.045970\n",
      "Iter 13/100 | Avg. Anisotropic Loss: 0.045927\n",
      "Iter 14/100 | Avg. Anisotropic Loss: 0.045902\n",
      "Iter 15/100 | Avg. Anisotropic Loss: 0.045882\n",
      "Iter 16/100 | Avg. Anisotropic Loss: 0.045859\n",
      "Iter 17/100 | Avg. Anisotropic Loss: 0.045834\n",
      "Iter 18/100 | Avg. Anisotropic Loss: 0.045813\n",
      "Iter 19/100 | Avg. Anisotropic Loss: 0.045799\n",
      "Iter 20/100 | Avg. Anisotropic Loss: 0.045790\n",
      "Iter 21/100 | Avg. Anisotropic Loss: 0.045781\n",
      "Iter 22/100 | Avg. Anisotropic Loss: 0.045773\n",
      "Iter 23/100 | Avg. Anisotropic Loss: 0.045765\n",
      "Iter 24/100 | Avg. Anisotropic Loss: 0.045757\n",
      "Iter 25/100 | Avg. Anisotropic Loss: 0.045749\n",
      "Iter 26/100 | Avg. Anisotropic Loss: 0.045740\n",
      "Iter 27/100 | Avg. Anisotropic Loss: 0.045731\n",
      "Iter 28/100 | Avg. Anisotropic Loss: 0.045719\n",
      "Iter 29/100 | Avg. Anisotropic Loss: 0.045710\n",
      "Iter 30/100 | Avg. Anisotropic Loss: 0.045698\n",
      "Iter 31/100 | Avg. Anisotropic Loss: 0.045674\n",
      "Iter 32/100 | Avg. Anisotropic Loss: 0.045641\n",
      "Iter 33/100 | Avg. Anisotropic Loss: 0.045593\n",
      "Iter 34/100 | Avg. Anisotropic Loss: 0.045547\n",
      "Iter 35/100 | Avg. Anisotropic Loss: 0.045507\n",
      "Iter 36/100 | Avg. Anisotropic Loss: 0.045473\n",
      "Iter 37/100 | Avg. Anisotropic Loss: 0.045439\n",
      "Iter 38/100 | Avg. Anisotropic Loss: 0.045412\n",
      "Iter 39/100 | Avg. Anisotropic Loss: 0.045388\n",
      "Iter 40/100 | Avg. Anisotropic Loss: 0.045373\n",
      "Iter 41/100 | Avg. Anisotropic Loss: 0.045361\n",
      "Iter 42/100 | Avg. Anisotropic Loss: 0.045347\n",
      "Iter 43/100 | Avg. Anisotropic Loss: 0.045336\n",
      "Iter 44/100 | Avg. Anisotropic Loss: 0.045325\n",
      "Iter 45/100 | Avg. Anisotropic Loss: 0.045315\n",
      "Iter 46/100 | Avg. Anisotropic Loss: 0.045306\n",
      "Iter 47/100 | Avg. Anisotropic Loss: 0.045298\n",
      "Iter 48/100 | Avg. Anisotropic Loss: 0.045291\n",
      "Iter 49/100 | Avg. Anisotropic Loss: 0.045287\n",
      "Iter 50/100 | Avg. Anisotropic Loss: 0.045285\n",
      "Iter 51/100 | Avg. Anisotropic Loss: 0.045284\n",
      "Iter 52/100 | Avg. Anisotropic Loss: 0.045283\n",
      "Iter 53/100 | Avg. Anisotropic Loss: 0.045282\n",
      "Iter 54/100 | Avg. Anisotropic Loss: 0.045282\n",
      "Iter 55/100 | Avg. Anisotropic Loss: 0.045282\n",
      "Iter 56/100 | Avg. Anisotropic Loss: 0.045282\n",
      "Iter 57/100 | Avg. Anisotropic Loss: 0.045282\n",
      "Iter 58/100 | Avg. Anisotropic Loss: 0.045282\n",
      "Iter 59/100 | Avg. Anisotropic Loss: 0.045281\n",
      "Iter 60/100 | Avg. Anisotropic Loss: 0.045281\n",
      "Iter 61/100 | Avg. Anisotropic Loss: 0.045281\n",
      "Iter 62/100 | Avg. Anisotropic Loss: 0.045281\n",
      "Iter 63/100 | Avg. Anisotropic Loss: 0.045281\n",
      "Iter 64/100 | Avg. Anisotropic Loss: 0.045280\n",
      "Iter 65/100 | Avg. Anisotropic Loss: 0.045280\n",
      "Iter 66/100 | Avg. Anisotropic Loss: 0.045280\n",
      "Iter 67/100 | Avg. Anisotropic Loss: 0.045280\n",
      "subspace 6 - Converged after 67 iterations.\n",
      "--Training subspace 7 --\n",
      "Iter 1/100 | Avg. Anisotropic Loss: 0.051194\n",
      "Iter 2/100 | Avg. Anisotropic Loss: 0.044458\n",
      "Iter 3/100 | Avg. Anisotropic Loss: 0.042478\n",
      "Iter 4/100 | Avg. Anisotropic Loss: 0.041349\n",
      "Iter 5/100 | Avg. Anisotropic Loss: 0.040753\n",
      "Iter 6/100 | Avg. Anisotropic Loss: 0.040450\n",
      "Iter 7/100 | Avg. Anisotropic Loss: 0.040301\n",
      "Iter 8/100 | Avg. Anisotropic Loss: 0.040209\n",
      "Iter 9/100 | Avg. Anisotropic Loss: 0.040144\n",
      "Iter 10/100 | Avg. Anisotropic Loss: 0.040099\n",
      "Iter 11/100 | Avg. Anisotropic Loss: 0.040061\n",
      "Iter 12/100 | Avg. Anisotropic Loss: 0.040022\n",
      "Iter 13/100 | Avg. Anisotropic Loss: 0.039986\n",
      "Iter 14/100 | Avg. Anisotropic Loss: 0.039957\n",
      "Iter 15/100 | Avg. Anisotropic Loss: 0.039930\n",
      "Iter 16/100 | Avg. Anisotropic Loss: 0.039899\n",
      "Iter 17/100 | Avg. Anisotropic Loss: 0.039856\n",
      "Iter 18/100 | Avg. Anisotropic Loss: 0.039813\n",
      "Iter 19/100 | Avg. Anisotropic Loss: 0.039773\n",
      "Iter 20/100 | Avg. Anisotropic Loss: 0.039743\n",
      "Iter 21/100 | Avg. Anisotropic Loss: 0.039713\n",
      "Iter 22/100 | Avg. Anisotropic Loss: 0.039676\n",
      "Iter 23/100 | Avg. Anisotropic Loss: 0.039633\n",
      "Iter 24/100 | Avg. Anisotropic Loss: 0.039602\n",
      "Iter 25/100 | Avg. Anisotropic Loss: 0.039579\n",
      "Iter 26/100 | Avg. Anisotropic Loss: 0.039561\n",
      "Iter 27/100 | Avg. Anisotropic Loss: 0.039540\n",
      "Iter 28/100 | Avg. Anisotropic Loss: 0.039517\n",
      "Iter 29/100 | Avg. Anisotropic Loss: 0.039495\n",
      "Iter 30/100 | Avg. Anisotropic Loss: 0.039476\n",
      "Iter 31/100 | Avg. Anisotropic Loss: 0.039460\n",
      "Iter 32/100 | Avg. Anisotropic Loss: 0.039443\n",
      "Iter 33/100 | Avg. Anisotropic Loss: 0.039429\n",
      "Iter 34/100 | Avg. Anisotropic Loss: 0.039419\n",
      "Iter 35/100 | Avg. Anisotropic Loss: 0.039412\n",
      "Iter 36/100 | Avg. Anisotropic Loss: 0.039406\n",
      "Iter 37/100 | Avg. Anisotropic Loss: 0.039400\n",
      "Iter 38/100 | Avg. Anisotropic Loss: 0.039393\n",
      "Iter 39/100 | Avg. Anisotropic Loss: 0.039387\n",
      "Iter 40/100 | Avg. Anisotropic Loss: 0.039383\n",
      "Iter 41/100 | Avg. Anisotropic Loss: 0.039379\n",
      "Iter 42/100 | Avg. Anisotropic Loss: 0.039375\n",
      "Iter 43/100 | Avg. Anisotropic Loss: 0.039374\n",
      "Iter 44/100 | Avg. Anisotropic Loss: 0.039371\n",
      "Iter 45/100 | Avg. Anisotropic Loss: 0.039368\n",
      "Iter 46/100 | Avg. Anisotropic Loss: 0.039366\n",
      "Iter 47/100 | Avg. Anisotropic Loss: 0.039364\n",
      "Iter 48/100 | Avg. Anisotropic Loss: 0.039362\n",
      "Iter 49/100 | Avg. Anisotropic Loss: 0.039361\n",
      "Iter 50/100 | Avg. Anisotropic Loss: 0.039360\n",
      "Iter 51/100 | Avg. Anisotropic Loss: 0.039359\n",
      "Iter 52/100 | Avg. Anisotropic Loss: 0.039358\n",
      "Iter 53/100 | Avg. Anisotropic Loss: 0.039357\n",
      "Iter 54/100 | Avg. Anisotropic Loss: 0.039355\n",
      "Iter 55/100 | Avg. Anisotropic Loss: 0.039352\n",
      "Iter 56/100 | Avg. Anisotropic Loss: 0.039349\n",
      "Iter 57/100 | Avg. Anisotropic Loss: 0.039347\n",
      "Iter 58/100 | Avg. Anisotropic Loss: 0.039346\n",
      "Iter 59/100 | Avg. Anisotropic Loss: 0.039344\n",
      "Iter 60/100 | Avg. Anisotropic Loss: 0.039343\n",
      "Iter 61/100 | Avg. Anisotropic Loss: 0.039341\n",
      "Iter 62/100 | Avg. Anisotropic Loss: 0.039340\n",
      "Iter 63/100 | Avg. Anisotropic Loss: 0.039340\n",
      "Iter 64/100 | Avg. Anisotropic Loss: 0.039339\n",
      "Iter 65/100 | Avg. Anisotropic Loss: 0.039338\n",
      "Iter 66/100 | Avg. Anisotropic Loss: 0.039336\n",
      "Iter 67/100 | Avg. Anisotropic Loss: 0.039334\n",
      "Iter 68/100 | Avg. Anisotropic Loss: 0.039333\n",
      "Iter 69/100 | Avg. Anisotropic Loss: 0.039331\n",
      "Iter 70/100 | Avg. Anisotropic Loss: 0.039328\n",
      "Iter 71/100 | Avg. Anisotropic Loss: 0.039325\n",
      "Iter 72/100 | Avg. Anisotropic Loss: 0.039323\n",
      "Iter 73/100 | Avg. Anisotropic Loss: 0.039321\n",
      "Iter 74/100 | Avg. Anisotropic Loss: 0.039318\n",
      "Iter 75/100 | Avg. Anisotropic Loss: 0.039315\n",
      "Iter 76/100 | Avg. Anisotropic Loss: 0.039313\n",
      "Iter 77/100 | Avg. Anisotropic Loss: 0.039311\n",
      "Iter 78/100 | Avg. Anisotropic Loss: 0.039310\n",
      "Iter 79/100 | Avg. Anisotropic Loss: 0.039308\n",
      "Iter 80/100 | Avg. Anisotropic Loss: 0.039307\n",
      "Iter 81/100 | Avg. Anisotropic Loss: 0.039305\n",
      "Iter 82/100 | Avg. Anisotropic Loss: 0.039304\n",
      "Iter 83/100 | Avg. Anisotropic Loss: 0.039302\n",
      "Iter 84/100 | Avg. Anisotropic Loss: 0.039301\n",
      "Iter 85/100 | Avg. Anisotropic Loss: 0.039299\n",
      "Iter 86/100 | Avg. Anisotropic Loss: 0.039297\n",
      "Iter 87/100 | Avg. Anisotropic Loss: 0.039296\n",
      "Iter 88/100 | Avg. Anisotropic Loss: 0.039295\n",
      "Iter 89/100 | Avg. Anisotropic Loss: 0.039294\n",
      "Iter 90/100 | Avg. Anisotropic Loss: 0.039293\n",
      "Iter 91/100 | Avg. Anisotropic Loss: 0.039292\n",
      "Iter 92/100 | Avg. Anisotropic Loss: 0.039291\n",
      "Iter 93/100 | Avg. Anisotropic Loss: 0.039291\n",
      "Iter 94/100 | Avg. Anisotropic Loss: 0.039290\n",
      "Iter 95/100 | Avg. Anisotropic Loss: 0.039289\n",
      "Iter 96/100 | Avg. Anisotropic Loss: 0.039288\n",
      "Iter 97/100 | Avg. Anisotropic Loss: 0.039287\n",
      "Iter 98/100 | Avg. Anisotropic Loss: 0.039287\n",
      "Iter 99/100 | Avg. Anisotropic Loss: 0.039286\n",
      "Iter 100/100 | Avg. Anisotropic Loss: 0.039285\n",
      "--Training subspace 8 --\n",
      "Iter 1/100 | Avg. Anisotropic Loss: 0.118186\n",
      "Iter 2/100 | Avg. Anisotropic Loss: 0.061784\n",
      "Iter 3/100 | Avg. Anisotropic Loss: 0.055550\n",
      "Iter 4/100 | Avg. Anisotropic Loss: 0.053251\n",
      "Iter 5/100 | Avg. Anisotropic Loss: 0.052147\n",
      "Iter 6/100 | Avg. Anisotropic Loss: 0.051533\n",
      "Iter 7/100 | Avg. Anisotropic Loss: 0.051132\n",
      "Iter 8/100 | Avg. Anisotropic Loss: 0.050848\n",
      "Iter 9/100 | Avg. Anisotropic Loss: 0.050646\n",
      "Iter 10/100 | Avg. Anisotropic Loss: 0.050482\n",
      "Iter 11/100 | Avg. Anisotropic Loss: 0.050348\n",
      "Iter 12/100 | Avg. Anisotropic Loss: 0.050208\n",
      "Iter 13/100 | Avg. Anisotropic Loss: 0.050092\n",
      "Iter 14/100 | Avg. Anisotropic Loss: 0.049996\n",
      "Iter 15/100 | Avg. Anisotropic Loss: 0.049906\n",
      "Iter 16/100 | Avg. Anisotropic Loss: 0.049839\n",
      "Iter 17/100 | Avg. Anisotropic Loss: 0.049786\n",
      "Iter 18/100 | Avg. Anisotropic Loss: 0.049749\n",
      "Iter 19/100 | Avg. Anisotropic Loss: 0.049707\n",
      "Iter 20/100 | Avg. Anisotropic Loss: 0.049669\n",
      "Iter 21/100 | Avg. Anisotropic Loss: 0.049639\n",
      "Iter 22/100 | Avg. Anisotropic Loss: 0.049617\n",
      "Iter 23/100 | Avg. Anisotropic Loss: 0.049607\n",
      "Iter 24/100 | Avg. Anisotropic Loss: 0.049601\n",
      "Iter 25/100 | Avg. Anisotropic Loss: 0.049593\n",
      "Iter 26/100 | Avg. Anisotropic Loss: 0.049585\n",
      "Iter 27/100 | Avg. Anisotropic Loss: 0.049580\n",
      "Iter 28/100 | Avg. Anisotropic Loss: 0.049576\n",
      "Iter 29/100 | Avg. Anisotropic Loss: 0.049572\n",
      "Iter 30/100 | Avg. Anisotropic Loss: 0.049569\n",
      "Iter 31/100 | Avg. Anisotropic Loss: 0.049566\n",
      "Iter 32/100 | Avg. Anisotropic Loss: 0.049564\n",
      "Iter 33/100 | Avg. Anisotropic Loss: 0.049561\n",
      "Iter 34/100 | Avg. Anisotropic Loss: 0.049560\n",
      "Iter 35/100 | Avg. Anisotropic Loss: 0.049559\n",
      "Iter 36/100 | Avg. Anisotropic Loss: 0.049557\n",
      "Iter 37/100 | Avg. Anisotropic Loss: 0.049556\n",
      "Iter 38/100 | Avg. Anisotropic Loss: 0.049554\n",
      "Iter 39/100 | Avg. Anisotropic Loss: 0.049553\n",
      "Iter 40/100 | Avg. Anisotropic Loss: 0.049551\n",
      "Iter 41/100 | Avg. Anisotropic Loss: 0.049549\n",
      "Iter 42/100 | Avg. Anisotropic Loss: 0.049548\n",
      "Iter 43/100 | Avg. Anisotropic Loss: 0.049546\n",
      "Iter 44/100 | Avg. Anisotropic Loss: 0.049544\n",
      "Iter 45/100 | Avg. Anisotropic Loss: 0.049541\n",
      "Iter 46/100 | Avg. Anisotropic Loss: 0.049538\n",
      "Iter 47/100 | Avg. Anisotropic Loss: 0.049535\n",
      "Iter 48/100 | Avg. Anisotropic Loss: 0.049533\n",
      "Iter 49/100 | Avg. Anisotropic Loss: 0.049532\n",
      "Iter 50/100 | Avg. Anisotropic Loss: 0.049531\n",
      "Iter 51/100 | Avg. Anisotropic Loss: 0.049530\n",
      "Iter 52/100 | Avg. Anisotropic Loss: 0.049529\n",
      "Iter 53/100 | Avg. Anisotropic Loss: 0.049528\n",
      "Iter 54/100 | Avg. Anisotropic Loss: 0.049527\n",
      "Iter 55/100 | Avg. Anisotropic Loss: 0.049526\n",
      "Iter 56/100 | Avg. Anisotropic Loss: 0.049524\n",
      "Iter 57/100 | Avg. Anisotropic Loss: 0.049523\n",
      "Iter 58/100 | Avg. Anisotropic Loss: 0.049522\n",
      "Iter 59/100 | Avg. Anisotropic Loss: 0.049521\n",
      "Iter 60/100 | Avg. Anisotropic Loss: 0.049521\n",
      "Iter 61/100 | Avg. Anisotropic Loss: 0.049521\n",
      "Iter 62/100 | Avg. Anisotropic Loss: 0.049520\n",
      "Iter 63/100 | Avg. Anisotropic Loss: 0.049520\n",
      "Iter 64/100 | Avg. Anisotropic Loss: 0.049520\n",
      "Iter 65/100 | Avg. Anisotropic Loss: 0.049520\n",
      "subspace 8 - Converged after 65 iterations.\n",
      "--Training subspace 9 --\n",
      "Iter 1/100 | Avg. Anisotropic Loss: 0.067962\n",
      "Iter 2/100 | Avg. Anisotropic Loss: 0.050868\n",
      "Iter 3/100 | Avg. Anisotropic Loss: 0.049111\n",
      "Iter 4/100 | Avg. Anisotropic Loss: 0.048566\n",
      "Iter 5/100 | Avg. Anisotropic Loss: 0.048284\n",
      "Iter 6/100 | Avg. Anisotropic Loss: 0.048075\n",
      "Iter 7/100 | Avg. Anisotropic Loss: 0.047875\n",
      "Iter 8/100 | Avg. Anisotropic Loss: 0.047675\n",
      "Iter 9/100 | Avg. Anisotropic Loss: 0.047493\n",
      "Iter 10/100 | Avg. Anisotropic Loss: 0.047302\n",
      "Iter 11/100 | Avg. Anisotropic Loss: 0.047141\n",
      "Iter 12/100 | Avg. Anisotropic Loss: 0.047002\n",
      "Iter 13/100 | Avg. Anisotropic Loss: 0.046881\n",
      "Iter 14/100 | Avg. Anisotropic Loss: 0.046772\n",
      "Iter 15/100 | Avg. Anisotropic Loss: 0.046665\n",
      "Iter 16/100 | Avg. Anisotropic Loss: 0.046572\n",
      "Iter 17/100 | Avg. Anisotropic Loss: 0.046503\n",
      "Iter 18/100 | Avg. Anisotropic Loss: 0.046440\n",
      "Iter 19/100 | Avg. Anisotropic Loss: 0.046386\n",
      "Iter 20/100 | Avg. Anisotropic Loss: 0.046337\n",
      "Iter 21/100 | Avg. Anisotropic Loss: 0.046286\n",
      "Iter 22/100 | Avg. Anisotropic Loss: 0.046256\n",
      "Iter 23/100 | Avg. Anisotropic Loss: 0.046235\n",
      "Iter 24/100 | Avg. Anisotropic Loss: 0.046217\n",
      "Iter 25/100 | Avg. Anisotropic Loss: 0.046202\n",
      "Iter 26/100 | Avg. Anisotropic Loss: 0.046181\n",
      "Iter 27/100 | Avg. Anisotropic Loss: 0.046155\n",
      "Iter 28/100 | Avg. Anisotropic Loss: 0.046127\n",
      "Iter 29/100 | Avg. Anisotropic Loss: 0.046102\n",
      "Iter 30/100 | Avg. Anisotropic Loss: 0.046079\n",
      "Iter 31/100 | Avg. Anisotropic Loss: 0.046066\n",
      "Iter 32/100 | Avg. Anisotropic Loss: 0.046054\n",
      "Iter 33/100 | Avg. Anisotropic Loss: 0.046041\n",
      "Iter 34/100 | Avg. Anisotropic Loss: 0.046028\n",
      "Iter 35/100 | Avg. Anisotropic Loss: 0.046018\n",
      "Iter 36/100 | Avg. Anisotropic Loss: 0.046007\n",
      "Iter 37/100 | Avg. Anisotropic Loss: 0.046000\n",
      "Iter 38/100 | Avg. Anisotropic Loss: 0.045994\n",
      "Iter 39/100 | Avg. Anisotropic Loss: 0.045988\n",
      "Iter 40/100 | Avg. Anisotropic Loss: 0.045980\n",
      "Iter 41/100 | Avg. Anisotropic Loss: 0.045973\n",
      "Iter 42/100 | Avg. Anisotropic Loss: 0.045962\n",
      "Iter 43/100 | Avg. Anisotropic Loss: 0.045954\n",
      "Iter 44/100 | Avg. Anisotropic Loss: 0.045949\n",
      "Iter 45/100 | Avg. Anisotropic Loss: 0.045944\n",
      "Iter 46/100 | Avg. Anisotropic Loss: 0.045939\n",
      "Iter 47/100 | Avg. Anisotropic Loss: 0.045933\n",
      "Iter 48/100 | Avg. Anisotropic Loss: 0.045929\n",
      "Iter 49/100 | Avg. Anisotropic Loss: 0.045925\n",
      "Iter 50/100 | Avg. Anisotropic Loss: 0.045922\n",
      "Iter 51/100 | Avg. Anisotropic Loss: 0.045920\n",
      "Iter 52/100 | Avg. Anisotropic Loss: 0.045919\n",
      "Iter 53/100 | Avg. Anisotropic Loss: 0.045918\n",
      "Iter 54/100 | Avg. Anisotropic Loss: 0.045917\n",
      "Iter 55/100 | Avg. Anisotropic Loss: 0.045915\n",
      "Iter 56/100 | Avg. Anisotropic Loss: 0.045914\n",
      "Iter 57/100 | Avg. Anisotropic Loss: 0.045914\n",
      "Iter 58/100 | Avg. Anisotropic Loss: 0.045914\n",
      "Iter 59/100 | Avg. Anisotropic Loss: 0.045913\n",
      "Iter 60/100 | Avg. Anisotropic Loss: 0.045913\n",
      "Iter 61/100 | Avg. Anisotropic Loss: 0.045913\n",
      "Iter 62/100 | Avg. Anisotropic Loss: 0.045912\n",
      "Iter 63/100 | Avg. Anisotropic Loss: 0.045911\n",
      "Iter 64/100 | Avg. Anisotropic Loss: 0.045910\n",
      "Iter 65/100 | Avg. Anisotropic Loss: 0.045910\n",
      "Iter 66/100 | Avg. Anisotropic Loss: 0.045909\n",
      "Iter 67/100 | Avg. Anisotropic Loss: 0.045909\n",
      "Iter 68/100 | Avg. Anisotropic Loss: 0.045909\n",
      "Iter 69/100 | Avg. Anisotropic Loss: 0.045909\n",
      "Iter 70/100 | Avg. Anisotropic Loss: 0.045909\n",
      "Iter 71/100 | Avg. Anisotropic Loss: 0.045909\n",
      "Iter 72/100 | Avg. Anisotropic Loss: 0.045909\n",
      "Iter 73/100 | Avg. Anisotropic Loss: 0.045909\n",
      "Iter 74/100 | Avg. Anisotropic Loss: 0.045909\n",
      "Iter 75/100 | Avg. Anisotropic Loss: 0.045909\n",
      "subspace 9 - Converged after 75 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 8, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training: PQ with anisotropic loss function\n",
    "n_iter = 100 # for training with anisotropic loss function\n",
    "scann_codebooks = np.zeros((n_subvectors, n_clusters, subvector_dim), dtype=np.float32)\n",
    "\n",
    "loss_tracking = []\n",
    "verbose = True\n",
    "for j, subspace in enumerate(subspaces):\n",
    "    centroids = np.array([subspace[np.random.choice(n_items)] for _ in range(n_clusters)]) \n",
    "    # # Kmeans : \n",
    "    # # \"We note that we can also optionally initialize the codebook by first training the codebook under \n",
    "    # # regular `2-reconstruction loss, which speed up training process\"\n",
    "    # kmeans = KMeans(n_clusters=n_clusters, \n",
    "    #     init='k-means++', n_init=1, max_iter=300).fit(subspace)\n",
    "    # centroids = kmeans.cluster_centers_\n",
    "    print(f\"--Training subspace {j} --\")\n",
    "    for i in range(n_iter):\n",
    "        # Step 2: Partition Assignment.\n",
    "        residuals = subspace[:, np.newaxis, :] - centroids\n",
    "        losses = anisotropic_loss(residuals, subspace[:, np.newaxis, :], eta=eta, verbose=False)\n",
    "        assignments = np.argmin(losses, axis=1).flatten()\n",
    "\n",
    "        # losses(10000, 8, 1). losses[0,0,0] represent anisotropic loss for 0th subvector to 0th centroid. losses[0, 1, 0] represent anisotropic loss for 0th subvector to 1st centroid, ...\n",
    "        # so np.min() => for each subvector, find the minimum anisotropic loss (centroid)\n",
    "        # np.mean() => average over all items\n",
    "        current_loss = np.mean(np.min(losses, axis=1))\n",
    "        loss_tracking.append({\n",
    "            \"eta\": eta,\n",
    "            \"subspace\": j,\n",
    "            \"iteration\": i,\n",
    "            \"loss\": current_loss\n",
    "        })\n",
    "        if verbose:\n",
    "            print(f\"Iter {i+1}/{n_iter} | Avg. Anisotropic Loss: {current_loss:.6f}\")\n",
    "        \n",
    "        # Step 3: Codebook update.\n",
    "        new_centroids = np.zeros(centroids.shape)\n",
    "        # The goal is to find the single new position for the centroid cj \n",
    "        # that minimizes the total anisotropic loss for all the points in its cluster, Xj\n",
    "        for k in range(n_clusters):\n",
    "            assigned_points = subspace[assignments == k]\n",
    "            if len(assigned_points) == 0:\n",
    "                # If a cluster is empty, re-initialize its centroid to a random point\n",
    "                new_centroids[k] = subspace[np.random.choice(n_items)]\n",
    "                continue\n",
    "            \n",
    "            # === Based on Theorem 4.2, with h_par = eta and h_orth = 1. ===\n",
    "            # Since our vectors are unit-norm, ||x||^2 is constant for the full vector,\n",
    "            # but not necessarily for the subvectors.\n",
    "\n",
    "            # This creates an identity matrix I and scales it by the subvector_dimension\n",
    "            A = len(assigned_points) * np.identity(subvector_dim, dtype=np.float32)\n",
    "            xxt_sum = np.zeros((subvector_dim, subvector_dim), dtype=np.float32)\n",
    "            for x in assigned_points:\n",
    "                x_norm_sq = np.sum(x**2)\n",
    "                xxt_sum += ((eta - 1) / x_norm_sq) * np.outer(x, x)\n",
    "            \n",
    "            # Right side of the equation: b = sum(eta*x)\n",
    "            b = eta * np.sum(assigned_points, axis=0)\n",
    "            \n",
    "            # simplified equation from theorem 4.2.\n",
    "            # LinAlgError: singular matrix\n",
    "            try:\n",
    "                new_centroids[k] = inv(A + xxt_sum) @ b\n",
    "            except np.linalg.LinAlgError:\n",
    "                # If matrix is singular, just keep the old centroid\n",
    "                new_centroids[k] = centroids[k]\n",
    "\n",
    "        # returns True if all elements are equal with a tolerance of 1e-5\n",
    "        if np.allclose(centroids, new_centroids, atol=1e-5):\n",
    "            print(f\"subspace {j} - Converged after {i+1} iterations.\")\n",
    "            break\n",
    "        centroids = new_centroids\n",
    "    # verbose = False\n",
    "    scann_codebooks[j] = centroids\n",
    "\n",
    "# After training, create a DataFrame to track all loss for each subspace\n",
    "loss_df = pd.DataFrame(loss_tracking)\n",
    "# Each row contains: subspace, iteration, all_losses (flattened), min_loss_per_item, avg_min_loss\n",
    "losses.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd3728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "subspace=0<br>iteration=%{x}<br>loss=%{y}<extra></extra>",
         "legendgroup": "0",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "0",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDEyMzQ=",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAoId+tD9L6dR2o+uuP/6kKAYajqw/RGLK5/nCqz8c6/AQEGmrP0OcRrtBIqs/TjGx/5vYqj+05HFLrJWqP8sByt2vWqo/Lw9Zn90lqj/Hpydoc/apPyyJT5oY16k/ufnB8r3CqT/uLAdo3LWpPxcTipp3rak/4oE46IKmqT9b7Q7VHaKpP4c0SLI9n6k/FvZkjtOdqT+7SjR1Cp2pP1kJ62VjnKk/oI6BDVibqT8OCAy/dZqpPzPouahkmak/jXXqI4iXqT+yBW0fvZWpP1HSPM3/k6k/5U4kiQ2SqT8fhsT2xJCpP/QUyQx/j6k/SU9ICYiOqT+ZLrThCY6pP92A4TrLjak/AJeGbJiNqT8yaoBxfY2pP64bXl5bjak/5XnGURiNqT9CfvRi1IypPzVD9c2YjKk/8K+WuWiMqT/Kqg+XSoypP9kXhjs+jKk/ZlFXXDqMqT9R1gKVNoypPzfU5Lo0jKk/oW4GAi+MqT+9YxFJJYypP5mbmUMhjKk/2eKDLx6MqT+1bPQwHYypP5UCGFQajKk/8bfeFhiMqT/wEvydF4ypPw==",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "subspace=1<br>iteration=%{x}<br>loss=%{y}<extra></extra>",
         "legendgroup": "1",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "1",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDEyMzQ1Njc4OTo7PD0+P0BBQkNERUZHSElKS0xNTk9QUVJTVFVWV1hZWls=",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAoNShsz83iYwPbWStP5q5uYtvo6s/49qJJD4Lqz+3PX/HicWqP4oiUcVSk6o/s69Atx92qj/gYv1HpWSqPzoevOyXWKo/aItRx7NQqj/1Q6cyqEqqP36xAFrtRao/zFsdOchBqj9/hTThEj6qP5/9Fik0Oqo/2c/U1U82qj8MuzTCtDGqP9juH1utLao/Syy+rWMpqj9tYCaS5SWqP4cyycmjIao/6X3rV7Meqj+6+cKttxyqP3rB+NxLG6o/mLjLo/sZqj/q+OzTchiqP3FxAUY0Fqo/CaEyMlMTqj8iUvt/RhCqPxvpNMafDKo/jfFWfv0Iqj8I12T2HQaqP+GjeZJSBKo/TZ8E/U4Cqj+hKCNLgACqP3Vb6qd//qk/hOD+3Kf8qT/utlHhH/upPxcWzkHP+ak/UCMhE3r4qT8FwUx17fapP2+Rp8xx9ak/ZLBlZy7zqT8nCM+q1vCpP1pB/Qcv76k/zAnKliHuqT+nfXbk6OypP2EzrU6O66k//l3eI5PpqT93/NhYfOepPwZFwjTb5Kk/1wjiegnhqT+5/QxjoNqpP+wTog9T0qk/pwVyjSbJqT910xoMkL6pP9nOksdts6k/GN0fIDClqT9h6mVc+4+pPyl6lnxXdqk/aw/SS0xhqT9U/XnStFOpP68pJwSfSqk/+63AvVZEqT9JbXojCUGpP/fwmjDTPqk/7Pxm8vA8qT+fqzaRTTupPzT9BivYOak/Zp85aaY4qT/bubSLqzepP79a4bgYN6k/w+2+dMQ2qT9YvI6ikjapP4P9n6NiNqk/MtWNIkQ2qT9UvouOJTapP0a/+OP3Nak/fliV9M81qT+bkzjfmTWpPyDmxLRiNak/ZqywuUs1qT9Y4XihOzWpP1q8wWYuNak/giyfDCc1qT9AmGUrEzWpP5Hni1X3NKk/ibcE3Oc0qT/Lsh/C3DSpP9LoFSzTNKk/Kde2J9A0qT/p9NayzzSpPw==",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "subspace=2<br>iteration=%{x}<br>loss=%{y}<extra></extra>",
         "legendgroup": "2",
         "line": {
          "color": "#00cc96",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "2",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDEyMzQ1Njc4OTo7PD0+P0BBQkNERUZHSElKS0xNTk9QUVJTVFVWV1hZWltcXV5fYGFiYw==",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAA4Pgesj/DgdRRv9muP6rZhmH0z60/D4zx83l4rT9bbWjX8EetP2rund3pJq0/lEYJPg8QrT/AHLz+RgGtP2c1WX2c96w/cXhLFerwrD/bKm2/T+usPwqo4sFa56w/8/NymLnjrD/tWrMLoOCsP7F9mGuD3qw/qZc4DAbdrD/Oeiaf+tusP8tQG0jh2qw/xxl0EPnZrD9LaZxlSdmsP9hUvNzM2Kw/dVqdIwnYrD/BUfc6K9esP/6zxniE1qw/Or4A/OPVrD/CdkBD89SsP+7kXobJ06w/rLhzel3SrD/qgV5GDtGsPxRykTrJz6w/Z9Cds0XOrD9YPgC1UcysP2mkPaDLyaw/8lx5k93HrD9Sf2N2F8asP6WQWBazxKw/HMffIIfDrD8ywsR9XsKsP82cxzGlwaw/70UwAB3BrD9pgzoqcsCsP1/bxBHIv6w/wZH5Yim/rD8QlSYOlL6sP5+T/eT7vaw/Eh9WNny9rD+opka4J72sP5J8+f4Cvaw/b0wc2eS8rD/2IIBdu7ysP2q1PLmWvKw/6CIsnGu8rD+f3NneQ7ysP0+0OLsfvKw/f6udBO+7rD/HZww3mLusP6pdLgAlu6w/dt+Kveu6rD9DECNfxbqsPx3gPDKBuqw/PoF3lyS6rD/na65Lw7msPysk0ANeuaw/5REPSwS5rD8C5kACurisP1KveRaHuKw/MB5sTES4rD9YOPSdFLisP2fQImTpt6w/8y4puou3rD9IAcD5IbesP1ZzFLuHtqw/aEEvEui1rD8dYBNuMbWsP1dnGwl+tKw/nDTpF+KzrD8KbKkahrOsPy78+lhOs6w/1oF2HfmyrD8VqGUypLKsP6L0FExmsqw/Sh+9dCayrD9YCJ248rGsP636oLresaw/IBWwhcyxrD+I5GQfxbGsP8Eatjm6saw/xdY/z6SxrD/ZJolHgrGsP6r03t5Lsaw/N7ZowySxrD+US/lb/7CsPw3VAjHzsKw/bf0emOGwrD9E+33L07CsP8NLxqq8sKw/oM1nQaWwrD8dyloCmbCsP9GZ96CKsKw/w5uX8HywrD8=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "subspace=3<br>iteration=%{x}<br>loss=%{y}<extra></extra>",
         "legendgroup": "3",
         "line": {
          "color": "#ab63fa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "3",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDEyMzQ1Njc4OTo7PD0+Pw==",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAwKbmsT8CjPqabkKrP7lqketCuqk/gtGXgtUXqT/cB2kVFreoPw6D7Zr9gag/7B0M65JeqD8irtO7VkaoP5oYQtWbL6g/B4MTpSwgqD9YxvLjVBGoPwf2ARADCKg/Wz/JWF8AqD8xuSUZZ/qnP/qqGTsc9qc/1tblfbfxpz8Iyn2XY+6nPxcf6mXg6qc/9xgvsmfopz+WFwHYxOanP0/IqwvO5ac/N/nqQNvkpz/HCmpav+OnP0DVRDzj4qc/3zwXqrvhpz/wfcileOCnP9mB0bx736c/1Z/B2nnepz++Z4+579ynP4NLGJi+26c/5+whrpfapz+dOUKjStmnP4MxmbCG16c/b3UtHCXWpz9JOTnmK9SnP8cX/UgF0ac/5SpIPL/Opz/p9p8/mM2nPzQmmhG7zKc/wZ62lsbLpz/eaV0d/8qnP2pZoEpQyqc/jzdrNnLJpz8XH7TqCsinP9sf6y+pxqc/jJIPGY/Fpz/hhT/0n8SnP/OKGVDYw6c/ueE0ul/Dpz/3BVvaA8OnP9GrDOylwqc/2lS3/GbCpz9Lstf4UMKnP4+R/v8/wqc/WeNGbiHCpz+onr5//sGnPzGT/iDmwac/cDJoNNnBpz/lejNAzcGnP1kW4N/Hwac/HRyGN8bBpz8UC9ajxcGnP+IN927Fwac/Q0R5PsXBpz8=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "subspace=4<br>iteration=%{x}<br>loss=%{y}<extra></extra>",
         "legendgroup": "4",
         "line": {
          "color": "#FFA15A",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "4",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDE=",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAYDSPsj+M7UDTj1uuP6EIimUurKw/AmTxslELrD9u20hZerOrP5xjoTANf6s/5wvsh+Fdqz8Q+PWDpESrPy78VBYJMas/sLu68v0iqz+Wmr/PVRirP96lYp74Eas/aMfGbBgOqz+2z3Er0AqrP0tEr0qMCKs/rri/zXoGqz/4Mrh40ASrP323tudyA6s/tGlr6I4Cqz+1g86QDgKrPwV0oUyXAas/ep5kOkMBqz/wo7Hy8gCrP6J1+4OpAKs/hrK4oXoAqz8aGYgUXQCrP2GXQuo+AKs/IDrKjCYAqz8qKvbN+v+qP7PSxObg/6o/eb0PmcT/qj9N0DF+jf+qP7Y8jmBU/6o/UhASkhj/qj8+LN/A/P6qP3Ej59Dj/qo/Y96k7LH+qj+e58NUhf6qPyj/v9Bm/qo/AtAZpkP+qj/+QMQ3Lf6qPyVVuwsk/qo/SIC95Bj+qj+4+q8WFv6qP2CFnQgU/qo/QD/B6RL+qj92n5gqD/6qP3dtQIQK/qo/QRWP0Aj+qj8kofmVCP6qPw==",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "subspace=5<br>iteration=%{x}<br>loss=%{y}<extra></extra>",
         "legendgroup": "5",
         "line": {
          "color": "#19d3f3",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "5",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDEyMzQ1Njc4OTo7PD0+P0BBQkNERUZHSElKS0xNTk9QUVJTVFVWV1hZWltcXV5fYGFiYw==",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAYLOBsD9AeIBnVxmrP7j/PtIDF6o/dh2E2jCJqT/W8Aip7RqpPySYhZsezag/m8cA/P2bqD9mQ5f8tHqoPxY7n8ioZag/aeWL+PVWqD+vg8We9U2oP7ies2LRR6g/hkJnr5VBqD9iXxWfbzyoP+5GQsmOOKg/PPqa3x02qD/1savjszOoP1bNsM+6Mag/GiAhk44vqD8k+cp3gyyoP4S6KTtDKag/2kJYNJAmqD+8/l9R0iOoPzn4EIQeIqg/3ntTOukgqD+RrRvfsx+oP8z3QXdhHqg//EnyikQdqD/dUBUn7huoP8pAFpwqGqg/AZR+e6IXqD9v+cGwjRWoP6/plf9hFKg/6OlRQ0oTqD/KuELpkhKoP8wUdPNpEag/6OxPGJEPqD9l2kBAsg2oP8ODjz+WDKg/0wLbEM8LqD8iHG7QFAuoP6GDie2GCqg/RAr47OsJqD9vaSGNegmoP2vDMr3MCKg/HwXAHCoIqD90g70vvweoPz9LBx9AB6g/tbWXv+8GqD8Ml2wTtgaoP+Zd9eh8Bqg/5r14AkIGqD809owWAwaoP/BOxQylBag/xM5IxDYFqD+etHKhvQSoPyAT2iSCBKg/Uj+BrTwEqD8nAB/2ugOoP5tm6ZYwA6g/k3xqiOQCqD+iH99vkgKoP/YjSnZQAqg/GzLg6h8CqD+w75ij+gGoPxNl5MPVAag/jHbZm7UBqD8Lov3LpAGoP/VLi4eTAag/b9prcIgBqD+cGC0PfwGoP95kna1wAag/eFLSElIBqD+aBZ8fMAGoP6UN7I4UAag/eJ5KZPsAqD+r4u/G3ACoPyGLwEaYAKg/gE8WdzAAqD91ZiNS3v+nPy17Y4l6/6c/HHuSowH/pz/2z721n/6nP9U6bwBp/qc/2ASoYiv+pz++g1mG5v2nP2F8Lh/C/ac/45GsA5D9pz/s6woOZf2nP1LDqfg+/ac/9V/Q0xT9pz/Weur38vynP3iK72i3/Kc/FUnH1j78pz8pMRgUUPunP1U2BPRg+qc/tdZyDZj5pz9ABdFQ7vinP7eZBJZe+Kc/M+e7/u/3pz8=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "subspace=6<br>iteration=%{x}<br>loss=%{y}<extra></extra>",
         "legendgroup": "6",
         "line": {
          "color": "#FF6692",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "6",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDEyMzQ1Njc4OTo7PD0+P0BBQg==",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAwOxqrz8UzkNGIlepPxtC7mZNX6g/Pu7r7/MbqD8xHO1NmfunPxzbKmlp46c/jilPL/XOpz/VKlTDjL2nPw9boQXlrKc/JTRoRsucpz+uJtvYZpGnP9qvILJqiac/gp4p/raDpz/SdECMZ4CnP/UBz9zmfac/FNTC4eF6pz+YSUdEgnenP+4jhlfNdKc/lkKnlP1ypz/QDi/J2HGnPyl8kR+mcKc/DJpDTJhvpz/TiMh6d26nP1EuQtCBbac/eDyVb1tspz+rBQWGQ2unPzQOFWIKaqc/XbBU7YBopz+WN4YQVWenPzMiBeyzZac/hx3go4lipz9uBQWaQl6nP10e+Df/V6c/HSXPqP5Rpz+lyAwuwUynP6oe8aY+SKc/ej5Pz8lDpz8/M51PMkCnP9UB9VUfPac/EkRIFxc7pz+O6omAhTmnP3628B/BN6c/6Fa+0E42pz8kIhhUyTSnP52/qFuEM6c/nosLN1kypz+G/qb2TzGnP5IDY8hcMKc/Nz0ZcNkvpz+72Vr2ly+nPzJ2ePNsL6c/kzjQi04vpz+0IEO4OS+nPzQQhp4uL6c/7vsy6Cgvpz9+yQ7qJS+nPx/L52EkL6c/waq15SMvpz+gBwjaIC+nP4El1owbL6c/yKjPXhQvpz/m2NuUEC+nP9fWiBoKL6c/H+hOBQEvpz8oKqzF+C6nP0dZeHL2Lqc/1oCywvUupz8=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "subspace=7<br>iteration=%{x}<br>loss=%{y}<extra></extra>",
         "legendgroup": "7",
         "line": {
          "color": "#B6E880",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "7",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDEyMzQ1Njc4OTo7PD0+P0BBQkNERUZHSElKS0xNTk9QUVJTVFVWV1hZWltcXV5fYGFiYw==",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAYBY2qj9yqQ+PKsOmPyCylIyrv6U/y2NuOrMrpT+GytHXkN2kP4pAmZ7ptaQ/0OvwOmGipD81cC0ANpakP4XsTtPNjaQ/NUqJQOqHpD+6tUwf2IKkP1vugODCfaQ/mIcufAx5pD8IZbs1LnWkPycKd9uscaQ/jdiiNZRtpD9EzrQP82ekP1ocd9FYYqQ/2+NHMRddpD9JAqF+IVmkP0kLX/FFVaQ/0kpBf2RQpD+T9T1T1kqkP/Ky9ke9RqQ/RxbVp8FDpD+7qKifSEGkPyABdZmjPqQ/F5cytIo7pD/qBUdJvjikPwNwz4E6NqQ/1Q9akx80pD8oG+no3zGkPygECfYOMKQ/nMAp6rcupD8d5McA1S2kP28hJ7X2LKQ/0owfJy4spD+t99ysXSukP3o99uKOKqQ/rkFmAP0ppD+sEUrIbCmkPwJ5Pgr5KKQ/voiCecoopD/qDLZJciikP6A6I0MFKKQ/NJSjR8MnpD8eeNbRfiekPz0fXVFBJ6Q/AZE/UBAnpD/eGqor+SakP0ZNjhXtJqQ/Dm7vycsmpD+fBiJvlSakPz6ArnlSJqQ/hGD0S+0lpD/GrIz3kyWkP8OTt147JaQ/lKZ0ihglpD/zC6ic7ySkP9k/nnu6JKQ/ACe8eI4kpD8cP4yubCSkP1xlzyhQJKQ/y2EzRzYkpD+wIohMFiSkP//o3iDkI6Q/MXQDCKYjpD+c5oymZiOkP5opSUQkI6Q/pQmF/csipD/7i9lKcCKkP7HFaDooIqQ/mkMfa9MhpD9+rFx9eiGkPzkQVxskIaQ/mtcwZdMgpD/l4Z0bnCCkP0GKfNxtIKQ/dtkOwjggpD/bibBAASCkPwImZNrKH6Q/FweSOJ8fpD/VFbqZZx+kP5OcJ+45H6Q/HWUw2AwfpD+CgjEowx6kPxkMYz2KHqQ/BS26qm0epD/EjkhWVh6kP9VPvpU3HqQ/YkO6FRUepD9Zo99W+x2kP1atL3jiHaQ/j1AHbNQdpD9Zy0BBtx2kPzmeTLyMHaQ/Pw7enHodpD+VIBgZZh2kPymtz5hTHaQ/11pTNTUdpD8=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "subspace=8<br>iteration=%{x}<br>loss=%{y}<extra></extra>",
         "legendgroup": "8",
         "line": {
          "color": "#FF97FF",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "8",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDEyMzQ1Njc4OTo7PD0+P0A=",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAwG1Bvj8fKAt/L6KvP2F27hsMcaw/yo/OQ75Dqz9NlaWJArOqP6dpmu2AYqo/uvPWevItqj+yx8B3wQiqP9zg7ig67qk/9sP9isDYqT9m+CBbOcepPyRWONPhtKk/wzyKR7ClqT/Rvi5zCpmpPwE1CthAjak/gHVChHWEqT+29zX8jH2pPwcrUveseKk/50UnozxzqT/DzJ3IRG6pPywoz5lLaqk/fOk/zmpnqT+Mw61vG2apP2FJOylDZak/ZpbYjjRkqT+wvgMqRWOpP7G9ql6MYqk/VyuwT/1hqT+Hu46dfmGpP6mAbmUWYak/fAk1JrxgqT9WazHwZGCpPxYknlAZYKk/tjOA3uVfqT8j1xYVvV+pP6GlMsOSX6k/1PlU51hfqT83fhWBMF+pP0YZN4P5Xqk/JAsk/sReqT9UQgkihF6pP11Wl1lMXqk/61bfsg1eqT/CTu1Q2F2pP4gDijB9Xak/818lyBFdqT/B7iPPtFypP9nhytluXKk/XaSTNjxcqT99L4EKIlypP63pmqX+W6k/jbeeQ99bqT8biXivu1upP4JrLNiPW6k/DlsXwG1bqT+siMxnQ1upP78+Q4UNW6k/Jqh8feZaqT9or/zZ1FqpP2oazHzJWqk/jCKhisBaqT9OkR4Kt1qpP7oV1/SuWqk/4kTWWK1aqT+3+u3erFqpPw==",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "subspace=9<br>iteration=%{x}<br>loss=%{y}<extra></extra>",
         "legendgroup": "9",
         "line": {
          "color": "#FECB52",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "9",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDEyMzQ1Njc4OTo7PD0+P0BBQkNERUZHSElK",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAYPRlsT+OEbQCWwuqP1yKGV8PJak/J0rTy6LdqD8w7gUHpLioP9D1FxA7nag/7pw+KxODqD+Ouf7e3mioP/iSFT/9UKg/4YiqlfM3qD9/B0SV5SKoP8yNy2qsEKg/QXGkZb0AqD8m2JxOcvKnPy9qWt985Kc/95BBSkjYpz+i1WvSRs+nP+vWADgMx6c/PUNp4O6/pz8OR80ZcbmnP28ktmHasqc/xoviEt6upz+T7eP4HKynP26Xyy7Kqac/KB+EZcKnpz/eQ310/qSnP51ga1SWoac/f6liRPWdpz/TpqP7tpqnP7CPZ3S4l6c/fb0TVv6Vpz8AyagSX5SnP2b+CyCrkqc/JwZ/dAWRpz/wrVjmsI+nPzfTcWxDjqc/ZsQznEiNpz/yOsLlgIynP7DDf52ti6c/DIIKC72Kpz+P6DqmxYmnP6zt+15liKc/HfyF1EmHpz+DB5rZqYanPxDEkcMEhqc/Kl4OVUqFpz90WlTvjoSnP96TUxbxg6c/MkmPW4SDpz8jUnggEYOnP93/A6jXgqc/rvrsVLGCpz/vtSxEjIKnP7cysZhsgqc/sdWzVTKCpz/jIyuSFIKnP3GiQVkCgqc/TePwsPyBpz+bYg1D+IGnPxSKLcnwgac/DFdTqNyBpz+NbhlqxIGnPx77qmSpgac//m8+242Bpz+Ozom2dYGnPyx48Phtgac/KRlv5WqBpz/RGhdQaIGnP7CcrZxkgac/VamUHWKBpz/aMN2HYYGnPzZtKOxggac/Xwk6sl+Bpz9JbOYZXoGnP3QNwk5dgac/",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Subspace"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Anisotropic PQ Loss per Subspace over Iterations. eta = 2.04"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Iteration"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "fig = px.line(\n",
    "    loss_df, \n",
    "    x=\"iteration\", \n",
    "    y=\"loss\", \n",
    "    color=\"subspace\",\n",
    "    markers=True,\n",
    "    title=f\"Anisotropic PQ Loss per Subspace over Iterations. eta = {eta}\"\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Iteration\",\n",
    "    yaxis_title=\"Loss\",\n",
    "    legend_title=\"Subspace\"\n",
    ")\n",
    "fig.show()›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc5b7a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5)\n",
      "(8, 5)\n",
      "(10000, 8, 5)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "residuals = (N, k, d) = (10000, 10, 16)\n",
    "    - axis0: number of items\n",
    "    - axis1: number of clusters\n",
    "    - axis2: residual of subvector and centroid\n",
    "Example:\n",
    "- residuals[0, 0] or residuals[0, 0, :] → residual for 0th subvector w.r.t. centroid 0.\n",
    "- residuals[0, 3] → residual for 0th subvector w.r.t. centroid 3.\n",
    "- residuals[0] → (10, 16) residuals for 0th subvector to all centroids.\n",
    "\"\"\"\n",
    "print(subspace.shape)\n",
    "print(centroids.shape)\n",
    "print(residuals.shape)\n",
    "\n",
    "assert (subspace[0] - centroids[0] == residuals[0, 0, :]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db77de86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 50)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_vectors_scann = []\n",
    "for v in item_embeddings:\n",
    "    q_vec = encode(v, scann_codebooks)\n",
    "    q_vectors_scann.append(q_vec)\n",
    "q_vectors_scann = np.array(q_vectors_scann, dtype=np.int8)\n",
    "\n",
    "scann_reconstructed_vectors = []\n",
    "for q_vec in q_vectors_scann:\n",
    "    reconstructed_vector = decode(q_vec, scann_codebooks)\n",
    "    scann_reconstructed_vectors.append(reconstructed_vector)\n",
    "scann_reconstructed_vectors = np.array(scann_reconstructed_vectors)\n",
    "scann_reconstructed_vectors.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45826caa",
   "metadata": {},
   "source": [
    "# 2. Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ce64bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_queries = 100\n",
    "# Exclude the first n_items (item_embeddings) and randomly sample n_queries queries\n",
    "query_candidates = embeddings_df.iloc[n_items:]\n",
    "query_sample = query_candidates.sample(n=n_queries, random_state=42)\n",
    "query_embeddings = np.stack(query_sample['vector'].values).astype(np.float32)\n",
    "query_embeddings /= norm(query_embeddings, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61e17bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing ground truth neighbors...\n",
      "\n",
      "--- Recall @k ---\n",
      "Recall@ 1: Standard PQ = 0.0300, ScaNN PQ = 0.0900\n",
      "Recall@ 5: Standard PQ = 0.1120, ScaNN PQ = 0.1100\n",
      "Recall@10: Standard PQ = 0.1590, ScaNN PQ = 0.1510\n",
      "Recall@20: Standard PQ = 0.1775, ScaNN PQ = 0.1940\n",
      "\n",
      "--- Recall 1@k ---\n",
      "Recall@ 1: Standard PQ = 0.0300, ScaNN PQ = 0.0900\n",
      "Recall@ 5: Standard PQ = 0.1200, ScaNN PQ = 0.1600\n",
      "Recall@10: Standard PQ = 0.2000, ScaNN PQ = 0.2200\n",
      "Recall@20: Standard PQ = 0.3000, ScaNN PQ = 0.3700\n"
     ]
    }
   ],
   "source": [
    "# 1. Compute Ground Truth (exact search)\n",
    "k_values = [1, 5, 10, 20]\n",
    "print(\"\\nComputing ground truth neighbors...\")\n",
    "# Don't forget we've already normalized item_embeddings \n",
    "# therefore cosine similarity is equivalent to inner product.\n",
    "ground_truth_scores = query_embeddings @ item_embeddings.T  # (n_queries, n_items)\n",
    "ground_truth_neighbors = {}\n",
    "for k in k_values:\n",
    "    ground_truth_neighbors[k] = np.argsort(-ground_truth_scores, axis=1)[:, :k]\n",
    "\n",
    "\n",
    "# 2. Approximate search with quantized representations\n",
    "def approximate_search_pq(query, reconstructed_items, k):\n",
    "    \"\"\"Search using reconstructed vectors\"\"\"\n",
    "    scores = query @ reconstructed_items.T\n",
    "    return np.argsort(-scores)[:k]\n",
    "\n",
    "\n",
    "# 3. Calculate Recall@k\n",
    "def calculate_recall_at_k(true_neighbors, approx_neighbors):\n",
    "    \"\"\"Calculate what fraction of true top-k are in approximate top-k\"\"\"\n",
    "    intersection = len(np.intersect1d(true_neighbors, approx_neighbors))\n",
    "    return intersection / len(true_neighbors)\n",
    "\n",
    "print(\"\\n--- Recall @k ---\")\n",
    "for k in k_values:\n",
    "    standard_recalls = []\n",
    "    scann_recalls = []\n",
    "    \n",
    "    for q_idx in range(len(query_embeddings)):\n",
    "        query = query_embeddings[q_idx]\n",
    "        true_neighbors = ground_truth_neighbors[k][q_idx]\n",
    "        \n",
    "        # Standard PQ\n",
    "        standard_approx = approximate_search_pq(query, reconstructed_vectors, k)\n",
    "        standard_recalls.append(calculate_recall_at_k(true_neighbors, standard_approx))\n",
    "        \n",
    "        # ScaNN PQ\n",
    "        scann_approx = approximate_search_pq(query, scann_reconstructed_vectors, k)\n",
    "        scann_recalls.append(calculate_recall_at_k(true_neighbors, scann_approx))\n",
    "    print(f\"Recall@{k:2d}: Standard PQ = {np.mean(standard_recalls):.4f}, ScaNN PQ = {np.mean(scann_recalls):.4f}\")\n",
    "\n",
    "\n",
    "# 4. Calculate Recall 1@k\n",
    "def calculate_recall_1_at_k(true_neighbors, approx_neighbors):\n",
    "    \"\"\"Calculate what fraction of true top-k are in approximate top-k\"\"\"\n",
    "    return 1 if true_neighbors[0] in approx_neighbors else 0\n",
    "\n",
    "print(\"\\n--- Recall 1@k ---\")\n",
    "for k in k_values:\n",
    "    standard_recalls = []\n",
    "    scann_recalls = []\n",
    "    \n",
    "    for q_idx in range(len(query_embeddings)):\n",
    "        query = query_embeddings[q_idx]\n",
    "        true_neighbors = ground_truth_neighbors[k][q_idx]\n",
    "        \n",
    "        # Standard PQ\n",
    "        standard_approx = approximate_search_pq(query, reconstructed_vectors, k)\n",
    "        standard_recalls.append(calculate_recall_1_at_k(true_neighbors, standard_approx))\n",
    "        \n",
    "        # ScaNN PQ\n",
    "        scann_approx = approximate_search_pq(query, scann_reconstructed_vectors, k)\n",
    "        scann_recalls.append(calculate_recall_1_at_k(true_neighbors, scann_approx))\n",
    "    \n",
    "    print(f\"Recall@{k:2d}: Standard PQ = {np.mean(standard_recalls):.4f}, ScaNN PQ = {np.mean(scann_recalls):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686964f3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LinePayPlus",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
